{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5257bb27",
   "metadata": {},
   "source": [
    "# Orthogonal RNN\n",
    "\n",
    "Train Orthogonal RNN for MNIST classification based on [this Paper](https://arxiv.org/pdf/1901.08428.pdf)\n",
    "\n",
    "NOTE: this example is still under development. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859c154",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96269c7",
   "metadata": {},
   "source": [
    "For each element in the input sequence, each layer computes the following function:\n",
    "$$h_t=\\tanh(W_{ih}x_t+b_{ih}+W_{hh}h_{t-1}+b_hh)$$\n",
    "\n",
    "where $h_{t}$ is the hidden state at time $t$, and $h_{t-1}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $o$. \n",
    "\n",
    "For each layer, we have the orthogonal constraint:\n",
    "$$ W_{hh}^T W_{hh} = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfdd50",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path. "
   ]
  },
  {
   "cell_type": "code",
   "id": "90ed32f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:34.620330Z",
     "start_time": "2025-04-20T23:33:32.932408Z"
    }
   },
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('.')\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct \n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pygranso.private.getObjGrad import getObjGradDL"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:34.626064Z",
     "start_time": "2025-04-20T23:33:34.621440Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "\n",
    "# fix the random seed\n",
    "torch.manual_seed(55272025)\n",
    "\n",
    "w = 8"
   ],
   "id": "f689ea212cbe52ff",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "17a1b7fe",
   "metadata": {},
   "source": [
    "## Data Initialization \n",
    "Specify torch device, neural network architecture, and generate data.\n",
    "\n",
    "NOTE: please specify path for downloading data.\n",
    "\n",
    "Use GPU for this problem. If no cuda device available, please set *device = torch.device('cpu')*"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b4842e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:36.427100Z",
     "start_time": "2025-04-20T23:33:34.626749Z"
    }
   },
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 1024\n",
    "\n",
    "\n",
    "double_precision = torch.double\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x,(batch_size,sequence_length,input_size))\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device, dtype=double_precision)\n",
    "        out, hidden = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "model.train()\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = './examples/data/mnist',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ") \n",
    "test_data = datasets.MNIST(\n",
    "    root = './examples/data/mnist',\n",
    "    train = False,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ") \n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                        batch_size=batch_size, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=1),\n",
    "    'test' : torch.utils.data.DataLoader(test_data, \n",
    "                                        batch_size=batch_size, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=1),\n",
    "}\n",
    "\n",
    "inputs, labels = next(iter(loaders['train']))\n",
    "inputs, labels = inputs.reshape(-1, sequence_length, input_size).to(device=device, dtype=double_precision), labels.to(device=device)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ec80716b",
   "metadata": {},
   "source": [
    "## Function Set-Up\n",
    "\n",
    "Encode the optimization variables, and objective and constraint functions.\n",
    "\n",
    "Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm."
   ]
  },
  {
   "cell_type": "code",
   "id": "fb360e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:36.431507Z",
     "start_time": "2025-04-20T23:33:36.428904Z"
    }
   },
   "source": [
    "def user_fn(model,inputs,labels):\n",
    "    # objective function    \n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(logits, labels)\n",
    "\n",
    "    A = list(model.parameters())[1]\n",
    "\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "    # special orthogonal group\n",
    "    \n",
    "    ce = pygransoStruct()\n",
    "\n",
    "    c1_vec = (A.T @ A \n",
    "              - torch.eye(hidden_size)\n",
    "              .to(device=device, dtype=double_precision)\n",
    "             ).reshape(1,-1)\n",
    "    \n",
    "    ce.c1 = torch.linalg.vector_norm(c1_vec,2) # l2 folding to reduce the total number of constraints\n",
    "    # ce.c2 = torch.det(A) - 1\n",
    "\n",
    "    # ce = None\n",
    "\n",
    "    return [f,ci,ce]\n",
    "\n",
    "comb_fn = lambda model : user_fn(model,inputs,labels)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "f0f55ace",
   "metadata": {},
   "source": [
    "## User Options\n",
    "Specify user-defined options for PyGRANSO "
   ]
  },
  {
   "cell_type": "code",
   "id": "f3a65b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:36.435310Z",
     "start_time": "2025-04-20T23:33:36.432051Z"
    }
   },
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "opts.opt_tol = 1e-3\n",
    "opts.viol_eq_tol = 1e-4\n",
    "# opts.maxit = 150\n",
    "# opts.fvalquit = 1e-6\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 50\n",
    "# opts.print_ascii = True\n",
    "# opts.limited_mem_size = 100\n",
    "opts.double_precision = True\n",
    "\n",
    "opts.mu0 = 1"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "754ba30a",
   "metadata": {},
   "source": [
    "## Initial Test \n",
    "Check initial accuracy of the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "id": "711f0e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:38.541653Z",
     "start_time": "2025-04-20T23:33:38.524266Z"
    }
   },
   "source": [
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Initial acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial acc = 8.79%\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "8bca18c7",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "id": "632976b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:27:29.485040Z",
     "start_time": "2025-04-20T23:24:54.237636Z"
    }
   },
   "source": [
    "start = time.time()\n",
    "soln = pygranso(var_spec= model, combined_fn = comb_fn, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001B[0m\u001B[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001B[0m\u001B[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001B[0m\u001B[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001B[0m\u001B[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001B[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2110                                                                     ║ \n",
      " # of inequality constraints        :      0                                                                     ║ \n",
      " # of equality constraints          :      1                                                                     ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  6.36966280589 ║  2.31442990364 ║   -  │ 4.055233 ║ -  │     1 │ 0.000000 ║     1 │ 0.722315   ║ \n",
      "  50 ║ 1.000000 │  0.97215462685 ║  0.81510712525 ║   -  │ 0.157048 ║ S  │     3 │ 0.250000 ║     1 │ 0.794053   ║ \n",
      " 100 ║ 1.000000 │  0.48743938441 ║  0.40138206990 ║   -  │ 0.086057 ║ S  │     4 │ 0.125000 ║     1 │ 0.643448   ║ \n",
      " 150 ║ 1.000000 │  0.26574773962 ║  0.19895820224 ║   -  │ 0.066790 ║ S  │     4 │ 0.125000 ║     1 │ 0.480973   ║ \n",
      " 200 ║ 1.000000 │  0.13960275570 ║  0.09987751603 ║   -  │ 0.039725 ║ S  │     5 │ 0.062500 ║     1 │ 0.435998   ║ \n",
      " 250 ║ 1.000000 │  0.08145476518 ║  0.05599974753 ║   -  │ 0.025455 ║ S  │     5 │ 0.062500 ║     1 │ 0.279553   ║ \n",
      " 300 ║ 1.000000 │  0.05581616206 ║  0.03988864487 ║   -  │ 0.015928 ║ S  │     6 │ 0.031250 ║     1 │ 0.726957   ║ \n",
      " 350 ║ 1.000000 │  0.04122194386 ║  0.03054955858 ║   -  │ 0.010672 ║ S  │     6 │ 0.031250 ║     1 │ 0.105967   ║ \n",
      " 400 ║ 1.000000 │  0.03224980506 ║  0.02260522365 ║   -  │ 0.009645 ║ S  │     5 │ 0.062500 ║     1 │ 0.331053   ║ \n",
      " 450 ║ 1.000000 │  0.02431021044 ║  0.01910210699 ║   -  │ 0.005208 ║ S  │     6 │ 0.031250 ║     1 │ 0.175560   ║ \n",
      " 500 ║ 1.000000 │  0.02076165507 ║  0.01648488718 ║   -  │ 0.004277 ║ S  │     6 │ 0.031250 ║     1 │ 0.094051   ║ \n",
      " 550 ║ 1.000000 │  0.01759704915 ║  0.01484566267 ║   -  │ 0.002751 ║ S  │     4 │ 0.125000 ║     1 │ 0.043493   ║ \n",
      " 600 ║ 1.000000 │  0.01574761602 ║  0.01335920131 ║   -  │ 0.002388 ║ S  │     9 │ 0.003906 ║     1 │ 0.313531   ║ \n",
      " 650 ║ 1.000000 │  0.01384708937 ║  0.01166341826 ║   -  │ 0.002184 ║ S  │     9 │ 0.003906 ║     1 │ 0.264857   ║ \n",
      " 700 ║ 1.000000 │  0.01253475853 ║  0.01054195269 ║   -  │ 0.001993 ║ S  │     6 │ 0.031250 ║     1 │ 1.285834   ║ \n",
      " 750 ║ 1.000000 │  0.01133685168 ║  0.00987128837 ║   -  │ 0.001466 ║ S  │    10 │ 0.001953 ║     1 │ 0.954325   ║ \n",
      " 800 ║ 1.000000 │  0.01046783058 ║  0.00931552517 ║   -  │ 0.001152 ║ S  │     6 │ 0.031250 ║     1 │ 0.966515   ║ \n",
      " 850 ║ 1.000000 │  0.00984018340 ║  0.00882764502 ║   -  │ 0.001013 ║ S  │     7 │ 0.015625 ║     1 │ 0.134808   ║ \n",
      " 900 ║ 1.000000 │  0.00934369342 ║  0.00849586464 ║   -  │ 8.48e-04 ║ S  │     7 │ 0.015625 ║     1 │ 0.817734   ║ \n",
      " 950 ║ 1.000000 │  0.00868265954 ║  0.00815622103 ║   -  │ 5.26e-04 ║ S  │     4 │ 0.125000 ║     1 │ 0.087604   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "1000 ║ 1.000000 │  0.00733556010 ║  0.00685255988 ║   -  │ 4.83e-04 ║ S  │     4 │ 0.125000 ║     1 │ 0.060887   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Optimization results:                                                                                            ║ \n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.00685255988 ║   -  │ 4.83e-04 ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.00685255988 ║   -  │ 4.83e-04 ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              1000                                                                                    ║ \n",
      "Function evaluations:    5288                                                                                    ║ \n",
      "PyGRANSO termination code: 4 --- max iterations reached.                                                         ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "Total Wall Time: 155.22996497154236s\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "21bff5fd",
   "metadata": {},
   "source": [
    "## Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "id": "8d846f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:27:29.519645Z",
     "start_time": "2025-04-20T23:27:29.487018Z"
    }
   },
   "source": [
    "torch.nn.utils.vector_to_parameters(soln.final.x, model.parameters())\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct/len(inputs))))  \n",
    "print(\"final feasibility = {}\".format(soln.final.tve))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final acc = 100.00%\n",
      "final feasibility = 0.0004830002235291609\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Test Accuracy",
   "id": "c8065b42a3a06dae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:27:31.434544Z",
     "start_time": "2025-04-20T23:27:29.520356Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs, labels = next(iter(loaders['test']))\n",
    "inputs, labels = inputs.reshape(-1, sequence_length, input_size).to(device=device, dtype=double_precision), labels.to(device=device)\n",
    "\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final test acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ],
   "id": "a389b2263da949a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test acc = 74.61%\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Exact Penalty with Adam",
   "id": "76f5a81d9b657fbd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:42.268929Z",
     "start_time": "2025-04-20T23:33:42.264603Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.nn.functional import one_hot"
   ],
   "id": "6912929758dcdf8e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:43.963783Z",
     "start_time": "2025-04-20T23:33:42.461287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "inputs, labels = next(iter(loaders['train']))\n",
    "inputs, labels = inputs.reshape(-1, sequence_length, input_size).to(device=device, dtype=double_precision), labels.to(device=device)"
   ],
   "id": "76b884454bef55de",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:43.967140Z",
     "start_time": "2025-04-20T23:33:43.965144Z"
    }
   },
   "cell_type": "code",
   "source": "val_dataloader = loaders['test']",
   "id": "8bb6ad6b8ca802e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:43.971251Z",
     "start_time": "2025-04-20T23:33:43.968504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def f(model, inputs, labels):\n",
    "    logits = model(inputs)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    return loss_fn(logits, labels)\n",
    "\n",
    "def penalty(model):\n",
    "    A = list(model.parameters())[1]\n",
    "    \n",
    "    # print(A)\n",
    "    \n",
    "    return torch.norm(A.T @ A - torch.eye(hidden_size), p=1)\n",
    "\n",
    "def phi1(model, mu):\n",
    "    return f(model, inputs, labels) + mu * penalty(model)"
   ],
   "id": "a2c5cd2d045d0837",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:33:43.976529Z",
     "start_time": "2025-04-20T23:33:43.973Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_loop(model, mu, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    loss = phi1(model, mu)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "def val_loop(dataloader, model):\n",
    "    model.eval()\n",
    "    # size = len(dataloader.dataset)\n",
    "    size = batch_size\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # for inputs, labels in dataloader:\n",
    "        inputs, labels = next(iter(loaders['test']))\n",
    "        inputs, labels = inputs.reshape(-1, sequence_length, input_size).to(device=device, dtype=double_precision), labels.to(device=device)\n",
    "        logits = model(inputs)\n",
    "        _, predicted = torch.max(logits.data, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    correct /= size\n",
    "    print(f\"Error: \\n Accuracy: {(100*correct):>0.1f}% \\n\")\n",
    "    return 100*correct"
   ],
   "id": "8b7039555d8fc170",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 100 inner epochs",
   "id": "84b31fd5f87d140"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:59:28.149209Z",
     "start_time": "2025-04-20T23:59:28.145885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def exact_penalty_with_adam(mu_rho, mu_eps):\n",
    "    # res_model = res_loss = res_accuracy = res_label_smoothing = res_optimizer = None\n",
    "    global model\n",
    "    model.train()\n",
    "    \n",
    "    mu = torch.tensor([1.], dtype=double_precision)\n",
    "\n",
    "    for iteration in range(1000):\n",
    "        print(\"Iter\", iteration)\n",
    "        \n",
    "        # Adam\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        # prev_accuracy = None\n",
    "        for t in range(100):\n",
    "            # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            train_loop(model, mu, optimizer)\n",
    "            # val_accuracy = val_loop(val_dataloader, model)\n",
    "            # if prev_accuracy is not None and val_accuracy > prev_accuracy:\n",
    "            #     break\n",
    "            # prev_accuracy = val_accuracy\n",
    "        \n",
    "        # Exact penalty update\n",
    "        h = penalty(model)\n",
    "        print(\"Objective:\", f(model, inputs, labels))\n",
    "        val_accuracy = val_loop(val_dataloader, model)\n",
    "        print(\"Val accuracy:\", val_accuracy)\n",
    "        print(\"Penalty parameter:\", mu)\n",
    "        print(\"Penalty:\", h)\n",
    "        if h < 1e-3:  # if h(xk ) ≤ τ\n",
    "            break\n",
    "\n",
    "        # Choose new penalty parameter µk+1 > µk ;\n",
    "        if mu * h > mu_eps:\n",
    "            mu *= mu_rho\n",
    "\n",
    "        # Choose new starting point (stay as optimal x1, x2)\n",
    "\n",
    "        print()"
   ],
   "id": "a2df0f157d988e1a",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Hits around 64% acc at iter ~20",
   "id": "6cc4efba1457096b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T00:00:57.919406Z",
     "start_time": "2025-04-20T23:59:29.276834Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "exact_penalty_with_adam(mu_rho=1.1, mu_eps=1e-5)"
   ],
   "id": "fcdc27b5cfc04ad6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Objective: tensor(2.2073, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 19.1% \n",
      "\n",
      "Val accuracy: 19.140625\n",
      "Penalty parameter: tensor([1.], dtype=torch.float64)\n",
      "Penalty: tensor(27.6102, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 1\n",
      "Objective: tensor(2.0059, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 34.5% \n",
      "\n",
      "Val accuracy: 34.47265625\n",
      "Penalty parameter: tensor([1.1000], dtype=torch.float64)\n",
      "Penalty: tensor(21.4146, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 2\n",
      "Objective: tensor(1.8096, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 34.6% \n",
      "\n",
      "Val accuracy: 34.5703125\n",
      "Penalty parameter: tensor([1.2100], dtype=torch.float64)\n",
      "Penalty: tensor(17.3110, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 3\n",
      "Objective: tensor(1.6743, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 38.5% \n",
      "\n",
      "Val accuracy: 38.4765625\n",
      "Penalty parameter: tensor([1.3310], dtype=torch.float64)\n",
      "Penalty: tensor(12.7697, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 4\n",
      "Objective: tensor(1.5872, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 41.3% \n",
      "\n",
      "Val accuracy: 41.30859375\n",
      "Penalty parameter: tensor([1.4641], dtype=torch.float64)\n",
      "Penalty: tensor(9.2322, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 5\n",
      "Objective: tensor(1.4859, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 41.0% \n",
      "\n",
      "Val accuracy: 41.015625\n",
      "Penalty parameter: tensor([1.6105], dtype=torch.float64)\n",
      "Penalty: tensor(6.7301, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 6\n",
      "Objective: tensor(1.3742, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 47.2% \n",
      "\n",
      "Val accuracy: 47.16796875\n",
      "Penalty parameter: tensor([1.7716], dtype=torch.float64)\n",
      "Penalty: tensor(5.2307, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 7\n",
      "Objective: tensor(1.2734, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 47.7% \n",
      "\n",
      "Val accuracy: 47.65625\n",
      "Penalty parameter: tensor([1.9487], dtype=torch.float64)\n",
      "Penalty: tensor(4.1724, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 8\n",
      "Objective: tensor(1.1833, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 49.8% \n",
      "\n",
      "Val accuracy: 49.8046875\n",
      "Penalty parameter: tensor([2.1436], dtype=torch.float64)\n",
      "Penalty: tensor(3.4485, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 9\n",
      "Objective: tensor(1.1068, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 52.1% \n",
      "\n",
      "Val accuracy: 52.05078125\n",
      "Penalty parameter: tensor([2.3579], dtype=torch.float64)\n",
      "Penalty: tensor(2.7599, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 10\n",
      "Objective: tensor(1.0389, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 52.1% \n",
      "\n",
      "Val accuracy: 52.1484375\n",
      "Penalty parameter: tensor([2.5937], dtype=torch.float64)\n",
      "Penalty: tensor(2.1554, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 11\n",
      "Objective: tensor(0.9757, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 54.4% \n",
      "\n",
      "Val accuracy: 54.39453125\n",
      "Penalty parameter: tensor([2.8531], dtype=torch.float64)\n",
      "Penalty: tensor(1.5321, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 12\n",
      "Objective: tensor(0.9234, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 56.2% \n",
      "\n",
      "Val accuracy: 56.25\n",
      "Penalty parameter: tensor([3.1384], dtype=torch.float64)\n",
      "Penalty: tensor(1.1458, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 13\n",
      "Objective: tensor(0.8773, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 57.7% \n",
      "\n",
      "Val accuracy: 57.71484375\n",
      "Penalty parameter: tensor([3.4523], dtype=torch.float64)\n",
      "Penalty: tensor(0.7463, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 14\n",
      "Objective: tensor(0.8376, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 55.1% \n",
      "\n",
      "Val accuracy: 55.078125\n",
      "Penalty parameter: tensor([3.7975], dtype=torch.float64)\n",
      "Penalty: tensor(0.4926, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 15\n",
      "Objective: tensor(0.8004, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 57.4% \n",
      "\n",
      "Val accuracy: 57.421875\n",
      "Penalty parameter: tensor([4.1772], dtype=torch.float64)\n",
      "Penalty: tensor(0.3248, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 16\n",
      "Objective: tensor(0.7647, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 55.1% \n",
      "\n",
      "Val accuracy: 55.078125\n",
      "Penalty parameter: tensor([4.5950], dtype=torch.float64)\n",
      "Penalty: tensor(0.2318, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 17\n",
      "Objective: tensor(0.7345, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 56.5% \n",
      "\n",
      "Val accuracy: 56.54296875\n",
      "Penalty parameter: tensor([5.0545], dtype=torch.float64)\n",
      "Penalty: tensor(0.2180, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 18\n",
      "Objective: tensor(0.7061, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 57.8% \n",
      "\n",
      "Val accuracy: 57.8125\n",
      "Penalty parameter: tensor([5.5599], dtype=torch.float64)\n",
      "Penalty: tensor(0.2220, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 19\n",
      "Objective: tensor(0.6803, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 59.4% \n",
      "\n",
      "Val accuracy: 59.375\n",
      "Penalty parameter: tensor([6.1159], dtype=torch.float64)\n",
      "Penalty: tensor(0.2160, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 20\n",
      "Objective: tensor(0.6565, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 58.7% \n",
      "\n",
      "Val accuracy: 58.69140625\n",
      "Penalty parameter: tensor([6.7275], dtype=torch.float64)\n",
      "Penalty: tensor(0.2139, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 21\n",
      "Objective: tensor(0.6349, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 58.7% \n",
      "\n",
      "Val accuracy: 58.69140625\n",
      "Penalty parameter: tensor([7.4002], dtype=torch.float64)\n",
      "Penalty: tensor(0.2192, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 22\n",
      "Objective: tensor(0.6155, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 59.2% \n",
      "\n",
      "Val accuracy: 59.1796875\n",
      "Penalty parameter: tensor([8.1403], dtype=torch.float64)\n",
      "Penalty: tensor(0.2150, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 23\n",
      "Objective: tensor(0.5956, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 61.4% \n",
      "\n",
      "Val accuracy: 61.42578125\n",
      "Penalty parameter: tensor([8.9543], dtype=torch.float64)\n",
      "Penalty: tensor(0.2148, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 24\n",
      "Objective: tensor(0.5774, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 59.9% \n",
      "\n",
      "Val accuracy: 59.86328125\n",
      "Penalty parameter: tensor([9.8497], dtype=torch.float64)\n",
      "Penalty: tensor(0.2260, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 25\n",
      "Objective: tensor(0.5590, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 60.8% \n",
      "\n",
      "Val accuracy: 60.83984375\n",
      "Penalty parameter: tensor([10.8347], dtype=torch.float64)\n",
      "Penalty: tensor(0.2022, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 26\n",
      "Objective: tensor(0.5420, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 62.0% \n",
      "\n",
      "Val accuracy: 62.01171875\n",
      "Penalty parameter: tensor([11.9182], dtype=torch.float64)\n",
      "Penalty: tensor(0.2334, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 27\n",
      "Objective: tensor(0.5271, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 61.1% \n",
      "\n",
      "Val accuracy: 61.1328125\n",
      "Penalty parameter: tensor([13.1100], dtype=torch.float64)\n",
      "Penalty: tensor(0.2224, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 28\n",
      "Objective: tensor(0.5122, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 60.0% \n",
      "\n",
      "Val accuracy: 59.9609375\n",
      "Penalty parameter: tensor([14.4210], dtype=torch.float64)\n",
      "Penalty: tensor(0.2350, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 29\n",
      "Objective: tensor(0.4991, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 60.8% \n",
      "\n",
      "Val accuracy: 60.83984375\n",
      "Penalty parameter: tensor([15.8631], dtype=torch.float64)\n",
      "Penalty: tensor(0.2295, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 30\n",
      "Objective: tensor(0.4854, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/__init__.py\", line 405, in <module>\n",
      "    from torch._C import *  # noqa: F403\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<frozen importlib._bootstrap>\", line 463, in _lock_unlock_module\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/b_/m0xhq6xs3gx3hc0kzw7d8sw40000gn/T/ipykernel_76755/3459293493.py\", line 2, in <module>\n",
      "    exact_penalty_with_adam(mu_rho=1.1, mu_eps=1e-5)\n",
      "  File \"/var/folders/b_/m0xhq6xs3gx3hc0kzw7d8sw40000gn/T/ipykernel_76755/2929367869.py\", line 26, in exact_penalty_with_adam\n",
      "    val_accuracy = val_loop(val_dataloader, model)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/b_/m0xhq6xs3gx3hc0kzw7d8sw40000gn/T/ipykernel_76755/1923901322.py\", line 18, in val_loop\n",
      "    inputs, labels = next(iter(loaders['test']))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 708, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1458, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "                ^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1420, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "                    ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1251, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/queues.py\", line 113, in get\n",
      "    if not self._poll(timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 440, in _poll\n",
      "    r = wait([self], timeout)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/connection.py\", line 1136, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 2170, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1457, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1348, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1195, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 1110, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 991, in format_record\n",
      "    _format_traceback_lines(\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/IPython/core/ultratb.py\", line 215, in _format_traceback_lines\n",
      "    line = stack_line.render(pygmented=has_colors).rstrip('\\n') + '\\n'\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/stack_data/core.py\", line 391, in render\n",
      "    start_line, lines = self.frame_info._pygmented_scope_lines\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "                                               ^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/stack_data/core.py\", line 824, in _pygmented_scope_lines\n",
      "    lines = _pygmented_with_ranges(formatter, code, ranges)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/stack_data/utils.py\", line 170, in _pygmented_with_ranges\n",
      "    return highlighted.splitlines()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/signal_handling.py\", line 73, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 93035) is killed by signal: Interrupt: 2. \n"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T00:00:59.579412Z",
     "start_time": "2025-04-21T00:00:59.546714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ],
   "id": "fbab81ef8dba17f1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final acc = 83.98%\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 1000 inner epochs",
   "id": "79c689e653e8a4a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:45:46.147417Z",
     "start_time": "2025-04-20T23:45:46.142582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def exact_penalty_with_adam(mu_rho, mu_eps):\n",
    "    # res_model = res_loss = res_accuracy = res_label_smoothing = res_optimizer = None\n",
    "    global model\n",
    "    model.train()\n",
    "    \n",
    "    mu = torch.tensor([1.], dtype=double_precision)\n",
    "\n",
    "    for iteration in range(1000):\n",
    "        print(\"Iter\", iteration)\n",
    "        \n",
    "        # Adam\n",
    "        optimizer = torch.optim.Adam(model.parameters())\n",
    "        \n",
    "        # prev_accuracy = None\n",
    "        for t in range(1000):\n",
    "            # print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "            train_loop(model, mu, optimizer)\n",
    "            # val_accuracy = val_loop(val_dataloader, model)\n",
    "            # if prev_accuracy is not None and val_accuracy > prev_accuracy:\n",
    "            #     break\n",
    "            # prev_accuracy = val_accuracy\n",
    "            if t % 200 == 0:\n",
    "                print(\"Epoch\", t)\n",
    "        \n",
    "        # Exact penalty update\n",
    "        h = penalty(model)\n",
    "        print(\"Objective:\", f(model, inputs, labels))\n",
    "        val_accuracy = val_loop(val_dataloader, model)\n",
    "        print(\"Val accuracy:\", val_accuracy)\n",
    "        print(\"Penalty parameter:\", mu)\n",
    "        print(\"Penalty:\", h)\n",
    "        if h < 1e-3:  # if h(xk ) ≤ τ\n",
    "            break\n",
    "\n",
    "        # Choose new penalty parameter µk+1 > µk ;\n",
    "        if mu * h > mu_eps:\n",
    "            mu *= mu_rho\n",
    "\n",
    "        # Choose new starting point (stay as optimal x1, x2)\n",
    "\n",
    "        print()"
   ],
   "id": "c486f82bebbc7da",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:54:39.607642Z",
     "start_time": "2025-04-20T23:45:46.996936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "exact_penalty_with_adam(mu_rho=1.1, mu_eps=1e-5)"
   ],
   "id": "bd9218c6b6be7dcb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(1.1073, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 54.4% \n",
      "\n",
      "Val accuracy: 54.39453125\n",
      "Penalty parameter: tensor([1.], dtype=torch.float64)\n",
      "Penalty: tensor(2.1130, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 1\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.6417, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 59.6% \n",
      "\n",
      "Val accuracy: 59.5703125\n",
      "Penalty parameter: tensor([1.1000], dtype=torch.float64)\n",
      "Penalty: tensor(0.5604, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 2\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.4157, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 61.6% \n",
      "\n",
      "Val accuracy: 61.62109375\n",
      "Penalty parameter: tensor([1.2100], dtype=torch.float64)\n",
      "Penalty: tensor(0.2139, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 3\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.2850, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 59.6% \n",
      "\n",
      "Val accuracy: 59.5703125\n",
      "Penalty parameter: tensor([1.3310], dtype=torch.float64)\n",
      "Penalty: tensor(0.2009, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 4\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.2040, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 61.7% \n",
      "\n",
      "Val accuracy: 61.71875\n",
      "Penalty parameter: tensor([1.4641], dtype=torch.float64)\n",
      "Penalty: tensor(0.2004, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 5\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.1452, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 61.7% \n",
      "\n",
      "Val accuracy: 61.71875\n",
      "Penalty parameter: tensor([1.6105], dtype=torch.float64)\n",
      "Penalty: tensor(0.2007, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 6\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.1051, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 60.4% \n",
      "\n",
      "Val accuracy: 60.3515625\n",
      "Penalty parameter: tensor([1.7716], dtype=torch.float64)\n",
      "Penalty: tensor(0.1923, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 7\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0753, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 59.9% \n",
      "\n",
      "Val accuracy: 59.86328125\n",
      "Penalty parameter: tensor([1.9487], dtype=torch.float64)\n",
      "Penalty: tensor(0.1895, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 8\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0546, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 58.0% \n",
      "\n",
      "Val accuracy: 58.0078125\n",
      "Penalty parameter: tensor([2.1436], dtype=torch.float64)\n",
      "Penalty: tensor(0.2031, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 9\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0403, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 56.2% \n",
      "\n",
      "Val accuracy: 56.25\n",
      "Penalty parameter: tensor([2.3579], dtype=torch.float64)\n",
      "Penalty: tensor(0.2098, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 10\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0304, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 58.4% \n",
      "\n",
      "Val accuracy: 58.3984375\n",
      "Penalty parameter: tensor([2.5937], dtype=torch.float64)\n",
      "Penalty: tensor(0.1995, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 11\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0231, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 58.4% \n",
      "\n",
      "Val accuracy: 58.3984375\n",
      "Penalty parameter: tensor([2.8531], dtype=torch.float64)\n",
      "Penalty: tensor(0.2009, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 12\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0176, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 55.4% \n",
      "\n",
      "Val accuracy: 55.37109375\n",
      "Penalty parameter: tensor([3.1384], dtype=torch.float64)\n",
      "Penalty: tensor(0.2021, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 13\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0139, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 57.5% \n",
      "\n",
      "Val accuracy: 57.51953125\n",
      "Penalty parameter: tensor([3.4523], dtype=torch.float64)\n",
      "Penalty: tensor(0.1946, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 14\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0108, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 57.5% \n",
      "\n",
      "Val accuracy: 57.51953125\n",
      "Penalty parameter: tensor([3.7975], dtype=torch.float64)\n",
      "Penalty: tensor(0.1928, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 15\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0087, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 57.5% \n",
      "\n",
      "Val accuracy: 57.51953125\n",
      "Penalty parameter: tensor([4.1772], dtype=torch.float64)\n",
      "Penalty: tensor(0.2104, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 16\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0071, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 57.1% \n",
      "\n",
      "Val accuracy: 57.12890625\n",
      "Penalty parameter: tensor([4.5950], dtype=torch.float64)\n",
      "Penalty: tensor(0.2086, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 17\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0056, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 56.3% \n",
      "\n",
      "Val accuracy: 56.34765625\n",
      "Penalty parameter: tensor([5.0545], dtype=torch.float64)\n",
      "Penalty: tensor(0.2130, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 18\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0046, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 58.3% \n",
      "\n",
      "Val accuracy: 58.30078125\n",
      "Penalty parameter: tensor([5.5599], dtype=torch.float64)\n",
      "Penalty: tensor(0.2160, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 19\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0040, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 58.4% \n",
      "\n",
      "Val accuracy: 58.3984375\n",
      "Penalty parameter: tensor([6.1159], dtype=torch.float64)\n",
      "Penalty: tensor(0.2354, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 20\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0033, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 55.7% \n",
      "\n",
      "Val accuracy: 55.6640625\n",
      "Penalty parameter: tensor([6.7275], dtype=torch.float64)\n",
      "Penalty: tensor(0.2173, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 21\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0029, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 56.4% \n",
      "\n",
      "Val accuracy: 56.4453125\n",
      "Penalty parameter: tensor([7.4002], dtype=torch.float64)\n",
      "Penalty: tensor(0.2293, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 22\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0025, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 56.1% \n",
      "\n",
      "Val accuracy: 56.0546875\n",
      "Penalty parameter: tensor([8.1403], dtype=torch.float64)\n",
      "Penalty: tensor(0.2274, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 23\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0021, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 55.6% \n",
      "\n",
      "Val accuracy: 55.56640625\n",
      "Penalty parameter: tensor([8.9543], dtype=torch.float64)\n",
      "Penalty: tensor(0.2264, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 24\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0019, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 56.7% \n",
      "\n",
      "Val accuracy: 56.73828125\n",
      "Penalty parameter: tensor([9.8497], dtype=torch.float64)\n",
      "Penalty: tensor(0.2273, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 25\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0017, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 53.6% \n",
      "\n",
      "Val accuracy: 53.61328125\n",
      "Penalty parameter: tensor([10.8347], dtype=torch.float64)\n",
      "Penalty: tensor(0.2157, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 26\n",
      "Epoch 0\n",
      "Epoch 200\n",
      "Epoch 400\n",
      "Epoch 600\n",
      "Epoch 800\n",
      "Objective: tensor(0.0016, dtype=torch.float64, grad_fn=<NllLossBackward0>)\n",
      "Error: \n",
      " Accuracy: 56.3% \n",
      "\n",
      "Val accuracy: 56.34765625\n",
      "Penalty parameter: tensor([11.9182], dtype=torch.float64)\n",
      "Penalty: tensor(0.2263, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)\n",
      "\n",
      "Iter 27\n",
      "Epoch 0\n",
      "Epoch 200\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[26], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model \u001B[38;5;241m=\u001B[39m RNN(input_size, hidden_size, num_layers, num_classes)\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice, dtype\u001B[38;5;241m=\u001B[39mdouble_precision)\n\u001B[0;32m----> 2\u001B[0m \u001B[43mexact_penalty_with_adam\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmu_rho\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1.1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmu_eps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1e-5\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[25], line 17\u001B[0m, in \u001B[0;36mexact_penalty_with_adam\u001B[0;34m(mu_rho, mu_eps)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# prev_accuracy = None\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1000\u001B[39m):\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;66;03m# print(f\"Epoch {t+1}\\n-------------------------------\")\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m     \u001B[43mtrain_loop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m     \u001B[38;5;66;03m# val_accuracy = val_loop(val_dataloader, model)\u001B[39;00m\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;66;03m# if prev_accuracy is not None and val_accuracy > prev_accuracy:\u001B[39;00m\n\u001B[1;32m     20\u001B[0m     \u001B[38;5;66;03m#     break\u001B[39;00m\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;66;03m# prev_accuracy = val_accuracy\u001B[39;00m\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m t \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "Cell \u001B[0;32mIn[13], line 4\u001B[0m, in \u001B[0;36mtrain_loop\u001B[0;34m(model, mu, optimizer)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mtrain_loop\u001B[39m(model, mu, optimizer):\n\u001B[1;32m      2\u001B[0m     model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[0;32m----> 4\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mphi1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmu\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m      7\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "Cell \u001B[0;32mIn[12], line 14\u001B[0m, in \u001B[0;36mphi1\u001B[0;34m(model, mu)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mphi1\u001B[39m(model, mu):\n\u001B[0;32m---> 14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m mu \u001B[38;5;241m*\u001B[39m penalty(model)\n",
      "Cell \u001B[0;32mIn[12], line 2\u001B[0m, in \u001B[0;36mf\u001B[0;34m(model, inputs, labels)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mf\u001B[39m(model, inputs, labels):\n\u001B[0;32m----> 2\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     loss_fn \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss_fn(logits, labels)\n",
      "File \u001B[0;32m~/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[0;32mIn[5], line 28\u001B[0m, in \u001B[0;36mRNN.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     26\u001B[0m \u001B[38;5;66;03m# Set initial hidden and cell states \u001B[39;00m\n\u001B[1;32m     27\u001B[0m h0 \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\u001B[38;5;241m.\u001B[39mto(device\u001B[38;5;241m=\u001B[39mdevice, dtype\u001B[38;5;241m=\u001B[39mdouble_precision)\n\u001B[0;32m---> 28\u001B[0m out, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh0\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# out: tensor of shape (batch_size, seq_length, hidden_size)\u001B[39;00m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m#Reshaping the outputs such that it can be fit into the fully connected layer\u001B[39;00m\n\u001B[1;32m     30\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(out[:, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, :])\n",
      "File \u001B[0;32m~/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1737\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1738\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1739\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1745\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1746\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1747\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1748\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1749\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1750\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1752\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1753\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/torch/nn/modules/rnn.py:716\u001B[0m, in \u001B[0;36mRNN.forward\u001B[0;34m(self, input, hx)\u001B[0m\n\u001B[1;32m    714\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    715\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mRNN_TANH\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 716\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrnn_tanh\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    717\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    718\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    719\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m    720\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    721\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    722\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    723\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    724\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    725\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    726\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    727\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    728\u001B[0m         result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mrnn_relu(\n\u001B[1;32m    729\u001B[0m             \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m    730\u001B[0m             hx,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    737\u001B[0m             \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbatch_first,\n\u001B[1;32m    738\u001B[0m         )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-20T23:56:02.958720Z",
     "start_time": "2025-04-20T23:56:02.901604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ],
   "id": "b779c0e62c27ffd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final acc = 100.00%\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Adam overfits like crazy with many inner loops",
   "id": "6b3e98b73a3d41e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a30fcd39405cd95"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
