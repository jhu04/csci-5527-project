{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "regulated-degree",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bridal-masters",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:29:22.082186Z",
     "start_time": "2025-04-21T03:29:19.272797Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('.')\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct\n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "import torch.nn as nn\n",
    "# from torchvision import datasets\n",
    "# from torchvision.transforms import ToTensor\n",
    "# from pygranso.private.getObjGrad import getObjGradDL\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "informed-white",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:29:22.089471Z",
     "start_time": "2025-04-21T03:29:22.083696Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# fix the random seed\n",
    "torch.manual_seed(55272025)\n",
    "np.random.seed(5527)\n",
    "\n",
    "# w = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-heritage",
   "metadata": {},
   "source": [
    "## Model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "canadian-murder",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:29:27.082545Z",
     "start_time": "2025-04-21T03:29:22.090569Z"
    }
   },
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.linear_in = nn.Linear(input_size, hidden_size)\n",
    "        self.linear_hidden = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for i in range(num_layers - 1)])\n",
    "        self.linear_out = nn.Linear(hidden_size, 1)\n",
    "        self.activ = nn.Tanh()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_in(x)\n",
    "        x = self.activ(x)\n",
    "        for l in self.linear_hidden:\n",
    "            x = l(x)\n",
    "            x = self.activ(x)\n",
    "        out = self.linear_out(x)\n",
    "        return out\n",
    "    \n",
    "def get_grads(u, x, t):\n",
    "    u_t = torch.autograd.grad(\n",
    "        u, t,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    u_x = torch.autograd.grad(\n",
    "        u, x,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    u_xx = torch.autograd.grad(\n",
    "        u_x, x,\n",
    "        grad_outputs=torch.ones_like(u_x),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    return u_t,u_x,u_xx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-brick",
   "metadata": {},
   "source": [
    "## Data setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "furnished-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "double_precision = torch.double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sporting-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### START data setup\n",
    "data = scipy.io.loadmat('./data/burgers_shock.mat')\n",
    "\n",
    "# Get boundary points along three sides (x = -1, x = 1, t = 0)\n",
    "tb_x = data['t']\n",
    "xb_t = data['x']\n",
    "xb_xlow = np.full_like(tb_x, data['x'][0])\n",
    "xb_xhigh = np.full_like(tb_x, data['x'][-1])\n",
    "tb_tlow = np.full_like(xb_t, data['t'][0])\n",
    "\n",
    "usol_xlow = data['usol'][0,:,None]\n",
    "usol_xhigh = data['usol'][-1,:,None]\n",
    "usol_tlow = data['usol'][:,0,None]\n",
    "\n",
    "xb = np.vstack((xb_xlow, xb_xhigh, xb_t))\n",
    "tb = np.vstack((tb_x, tb_x, tb_tlow))\n",
    "usolb = np.vstack((usol_xlow, usol_xhigh, usol_tlow))\n",
    "\n",
    "xb = torch.Tensor(xb).to(device=device, dtype=double_precision).requires_grad_()\n",
    "tb = torch.Tensor(tb).to(device=device, dtype=double_precision).requires_grad_()\n",
    "usolb = torch.Tensor(usolb).to(device=device, dtype=double_precision).requires_grad_()\n",
    "\n",
    "# boundary_usol = usolb # point this global var at the right place\n",
    "\n",
    "boundary_points = (xb, tb)\n",
    "\n",
    "# Ground-truth data - used for testing/evaluation\n",
    "usol_full = data['usol']\n",
    "usol_tensor = usol_full.flatten()\n",
    "usol_tensor = torch.Tensor(usol_tensor).to(device=device, dtype=double_precision)\n",
    "\n",
    "# Sample points. Following Dual-Cone Gradient Descent, 10x as many sample points as boundary points\n",
    "n_samples = 4560\n",
    "xs = -1 + 2 * np.random.rand(n_samples, 1)\n",
    "ts = np.random.rand(n_samples, 1)\n",
    "\n",
    "xs = torch.Tensor(xs).to(device=device, dtype=double_precision).requires_grad_()\n",
    "ts = torch.Tensor(ts).to(device=device, dtype=double_precision).requires_grad_()\n",
    "sample_points = (xs, ts)\n",
    "\n",
    "# Create grid inputs for visualization, comparison to GT\n",
    "xgridsize = 256\n",
    "tgridsize = 100\n",
    "tv, xv = np.meshgrid(data['t'], data['x'])\n",
    "tv = torch.Tensor(tv.flatten()).to(device=device, dtype=double_precision).requires_grad_()\n",
    "xv = torch.Tensor(xv.flatten()).to(device=device, dtype=double_precision).requires_grad_()\n",
    "grid_points = torch.stack((xv, tv)).transpose(0,1)\n",
    "### END data setup\n",
    "###\n",
    "\n",
    "# Evaluates the relative L2 error over all grid points\n",
    "# Notably, this is NOT what the PINN is minimizing--it only has access to boundary points\n",
    "def evaluate(iteration, model, xv, tv, test_usol, error):\n",
    "    test_points = torch.stack((xv, tv)).transpose(0,1)\n",
    "    pred_usol = model(test_points)\n",
    "    L2_error = torch.norm(pred_usol - test_usol)\n",
    "    error[iteration-1] = L2_error.cpu().detach().item()\n",
    "\n",
    "    # Save intermediate results (NN outputs + PDE residuals) as images\n",
    "    if iteration % 25 == 0:\n",
    "        outimg = pred_usol.cpu().detach().numpy()\n",
    "        outimg = np.reshape(outimg, (xgridsize, tgridsize))\n",
    "        plt.imsave(\"output_imgs/predicted_\"+str(iteration)+\".png\", outimg, origin='upper')\n",
    "        plt.close()\n",
    "        evalu_t, evalu_x, evalu_xx = get_grads(pred_usol, xv, tv)\n",
    "        evalres = evalu_t + torch.flatten(pred_usol) * evalu_x - 0.01 / np.pi * evalu_xx\n",
    "        outimg = evalres.cpu().detach().numpy()\n",
    "        outimg = np.reshape(outimg, (xgridsize, tgridsize))\n",
    "        plt.imsave(\"output_imgs/pderesidual_\"+str(iteration)+\".png\", outimg, vmin=-3, vmax=3, origin='upper')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "small-contribution",
   "metadata": {},
   "source": [
    "# Exact Penalty with Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "capital-lighter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:29:27.141887Z",
     "start_time": "2025-04-21T03:29:27.139227Z"
    }
   },
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "test_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "assisted-turkish",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:29:27.150831Z",
     "start_time": "2025-04-21T03:29:27.148011Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(model, sample_points): # objective\n",
    "    x, t = sample_points\n",
    "    xt = torch.cat((x, t), 1)\n",
    "    u = model(xt)\n",
    "    \n",
    "    # Calculate gradients of network\n",
    "    u_t, u_x, u_xx = get_grads(u, x, t)\n",
    "    \n",
    "    # Minimize residual\n",
    "    res = u_t + u * u_x - 0.01 / np.pi * u_xx\n",
    "    objective = torch.norm(res) / res.numel()\n",
    "    return objective\n",
    "\n",
    "def penalty(model, boundary_points, boundary_usol):\n",
    "    xb, tb = boundary_points\n",
    "    xtb = torch.cat((xb, tb), 1)\n",
    "    ub = model(xtb)\n",
    "    \n",
    "    boundary_errors = ub - boundary_usol\n",
    "    return torch.norm(boundary_errors, p=1) / boundary_errors.numel()\n",
    "\n",
    "def l2_penalty(model, boundary_points, boundary_usol):\n",
    "    xb, tb = boundary_points\n",
    "    xtb = torch.cat((xb, tb), 1)\n",
    "    ub = model(xtb)\n",
    "    \n",
    "    boundary_errors = ub - boundary_usol\n",
    "    return torch.norm(boundary_errors, p=2) / boundary_errors.numel()\n",
    "\n",
    "# explicitly takes following arguments:\n",
    "# sample_points: Tensor(2, n_sample_points)\n",
    "# boundary_points: Tensor(2, n_boundary_points)\n",
    "# boundary_usol: Tensor(n_boundary_points)\n",
    "def phi1(model, mu, sample_points, boundary_points, boundary_usol):\n",
    "    return f(model, sample_points) + mu * penalty(model, boundary_points, boundary_usol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-advocacy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aging-trance",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:29:27.156619Z",
     "start_time": "2025-04-21T03:29:27.152110Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adam stuff\n",
    "\n",
    "def train_loop(model, mu, optimizer, f_lambda, penalty_lambda):\n",
    "    model.train()\n",
    "    \n",
    "    loss = f_lambda(model) + mu * penalty_lambda(model)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "# def val_loop(dataloader, model):\n",
    "#     model.eval()\n",
    "#     # size = len(dataloader.dataset)\n",
    "#     size = batch_size\n",
    "#     correct = 0\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         logits = model(inputs)\n",
    "#         _, predicted = torch.max(logits.data, 1)\n",
    "#         train_acc.append((predicted == labels).sum().item() / size)\n",
    "        \n",
    "#         logits = model(test_inputs)\n",
    "#         _, predicted = torch.max(logits.data, 1)\n",
    "#         c = (predicted == test_labels).sum().item()\n",
    "#         test_acc.append(c / size)\n",
    "#         correct += c\n",
    "    \n",
    "#     correct /= size\n",
    "#     print(f\"Error: \\n Accuracy: {(100*correct):>0.1f}% \\n\")\n",
    "#     return 100*correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contrary-commerce",
   "metadata": {},
   "source": [
    "### 1000 inner epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "motivated-facing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:29:27.161769Z",
     "start_time": "2025-04-21T03:29:27.157533Z"
    }
   },
   "outputs": [],
   "source": [
    "# `f_lambda` takes form `lambda model: loss_of_model_on_training_set`\n",
    "# `penalty_lambda` takes form `lambda model: penalty_of_model`\n",
    "# these two lambdas should have other required info (e.g. training points) already baked into them\n",
    "def exact_penalty_with_adam(model, f_lambda, penalty_lambda, mu_0=1., mu_rho=1.1, mu_eps=1e-5, n_inner_iters=1000, max_iters=100):\n",
    "    mu = torch.tensor([mu_0], dtype=double_precision).to(device)\n",
    "    h_prev = float('inf')\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "    # for iteration in range(1000):\n",
    "    resets = 0\n",
    "    for iteration in range(max_iters * n_inner_iters): # TODO: try smaller number of iterations (e.g. 2), and/or try Wenjie stopping strategy\n",
    "        update = iteration % 500 == 0\n",
    "        if update:\n",
    "            print(\"Iter\", iteration)\n",
    "        \n",
    "        train_loop(model, mu, optimizer, f_lambda, penalty_lambda)\n",
    "        \n",
    "        # Exact penalty update\n",
    "        \n",
    "        h = penalty_lambda(model)\n",
    "        if update:\n",
    "            print(\"Objective:\", f_lambda(model))\n",
    "            print(\"Penalty parameter:\", mu)\n",
    "            print(\"Penalty:\", h)\n",
    "        if h < 1e-5:  # if h(xk ) ≤ τ\n",
    "            break\n",
    "\n",
    "        # Choose new penalty parameter µk+1 > µk ;\n",
    "        # 100 inner iterations\n",
    "        if update and h > h_prev:\n",
    "            mu *= mu_rho\n",
    "            optimizer = torch.optim.Adam(model.parameters())\n",
    "            \n",
    "            resets += 1\n",
    "            print(\"Reset\", resets, \"times\")\n",
    "        if update:\n",
    "            h_prev = h\n",
    "\n",
    "        # Choose new starting point (stay as optimal x1, x2)\n",
    "\n",
    "        if update:\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "material-lancaster",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:33:25.419684Z",
     "start_time": "2025-04-21T03:29:27.163258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0\n",
      "Objective: tensor(6.7091e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1000], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.4909, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 500\n",
      "Objective: tensor(0.0092, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1000], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0412, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 1000\n",
      "Objective: tensor(0.0090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1000], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0276, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 1500\n",
      "Objective: tensor(0.0092, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1000], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0198, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 2000\n",
      "Objective: tensor(0.0089, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1000], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0210, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 1 times\n",
      "\n",
      "Iter 2500\n",
      "Objective: tensor(0.0090, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1100], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0161, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 3000\n",
      "Objective: tensor(0.0093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1100], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0139, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 3500\n",
      "Objective: tensor(0.0091, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1100], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0119, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 4000\n",
      "Objective: tensor(0.0087, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1100], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0252, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 2 times\n",
      "\n",
      "Iter 4500\n",
      "Objective: tensor(0.0087, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1210], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0066, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 5000\n",
      "Objective: tensor(0.0087, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1210], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0068, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 3 times\n",
      "\n",
      "Iter 5500\n",
      "Objective: tensor(0.0083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1331], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0095, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 4 times\n",
      "\n",
      "Iter 6000\n",
      "Objective: tensor(0.0083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1464], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0102, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 5 times\n",
      "\n",
      "Iter 6500\n",
      "Objective: tensor(0.0083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1611], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0168, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 6 times\n",
      "\n",
      "Iter 7000\n",
      "Objective: tensor(0.0081, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1772], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0104, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 7500\n",
      "Objective: tensor(0.0084, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1772], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0093, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 8000\n",
      "Objective: tensor(0.0081, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1772], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 8500\n",
      "Objective: tensor(0.0079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1772], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 9000\n",
      "Objective: tensor(0.0080, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1772], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0082, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 7 times\n",
      "\n",
      "Iter 9500\n",
      "Objective: tensor(0.0080, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1949], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 10000\n",
      "Objective: tensor(0.0080, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.1949], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0085, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 8 times\n",
      "\n",
      "Iter 10500\n",
      "Objective: tensor(0.0079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2144], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0065, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 11000\n",
      "Objective: tensor(0.0080, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2144], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0089, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 9 times\n",
      "\n",
      "Iter 11500\n",
      "Objective: tensor(0.0079, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2358], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0084, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 12000\n",
      "Objective: tensor(0.0078, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2358], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0063, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 12500\n",
      "Objective: tensor(0.0078, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2358], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 13000\n",
      "Objective: tensor(0.0077, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2358], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 13500\n",
      "Objective: tensor(0.0077, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2358], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0046, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 14000\n",
      "Objective: tensor(0.0075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2358], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 10 times\n",
      "\n",
      "Iter 14500\n",
      "Objective: tensor(0.0075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2594], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 11 times\n",
      "\n",
      "Iter 15000\n",
      "Objective: tensor(0.0075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2853], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0069, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 15500\n",
      "Objective: tensor(0.0075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.2853], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0071, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 12 times\n",
      "\n",
      "Iter 16000\n",
      "Objective: tensor(0.0075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.3138], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0046, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 16500\n",
      "Objective: tensor(0.0075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.3138], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 13 times\n",
      "\n",
      "Iter 17000\n",
      "Objective: tensor(0.0075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.3452], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 17500\n",
      "Objective: tensor(0.0075, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.3452], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 18000\n",
      "Objective: tensor(0.0074, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.3452], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 14 times\n",
      "\n",
      "Iter 18500\n",
      "Objective: tensor(0.0073, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.3797], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 15 times\n",
      "\n",
      "Iter 19000\n",
      "Objective: tensor(0.0072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.4177], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 19500\n",
      "Objective: tensor(0.0073, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.4177], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 20000\n",
      "Objective: tensor(0.0073, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.4177], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 16 times\n",
      "\n",
      "Iter 20500\n",
      "Objective: tensor(0.0072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.4595], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0027, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 21000\n",
      "Objective: tensor(0.0072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.4595], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 17 times\n",
      "\n",
      "Iter 21500\n",
      "Objective: tensor(0.0071, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.5054], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0027, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 22000\n",
      "Objective: tensor(0.0070, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.5054], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0096, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 18 times\n",
      "\n",
      "Iter 22500\n",
      "Objective: tensor(0.0070, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.5560], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 23000\n",
      "Objective: tensor(0.0069, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.5560], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0046, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 23500\n",
      "Objective: tensor(0.0068, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.5560], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0083, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 19 times\n",
      "\n",
      "Iter 24000\n",
      "Objective: tensor(0.0069, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.6116], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 24500\n",
      "Objective: tensor(0.0068, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.6116], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 25000\n",
      "Objective: tensor(0.0067, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.6116], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 20 times\n",
      "\n",
      "Iter 25500\n",
      "Objective: tensor(0.0067, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.6727], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 26000\n",
      "Objective: tensor(0.0066, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.6727], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 26500\n",
      "Objective: tensor(0.0066, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.6727], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0044, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 27000\n",
      "Objective: tensor(0.0065, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.6727], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 27500\n",
      "Objective: tensor(0.0065, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.6727], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0072, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 21 times\n",
      "\n",
      "Iter 28000\n",
      "Objective: tensor(0.0063, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.7400], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 28500\n",
      "Objective: tensor(0.0062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.7400], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0025, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 29000\n",
      "Objective: tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.7400], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0038, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 22 times\n",
      "\n",
      "Iter 29500\n",
      "Objective: tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.8140], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0041, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 23 times\n",
      "\n",
      "Iter 30000\n",
      "Objective: tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.8954], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0037, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 30500\n",
      "Objective: tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.8954], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0046, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 24 times\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 31000\n",
      "Objective: tensor(0.0056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([0.9850], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0070, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 25 times\n",
      "\n",
      "Iter 31500\n",
      "Objective: tensor(0.0056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.0835], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0035, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 32000\n",
      "Objective: tensor(0.0055, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.0835], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0071, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 26 times\n",
      "\n",
      "Iter 32500\n",
      "Objective: tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.1918], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0031, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 33000\n",
      "Objective: tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.1918], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 33500\n",
      "Objective: tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.1918], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0030, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 27 times\n",
      "\n",
      "Iter 34000\n",
      "Objective: tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.3110], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0044, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 28 times\n",
      "\n",
      "Iter 34500\n",
      "Objective: tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.4421], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 35000\n",
      "Objective: tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.4421], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0024, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 29 times\n",
      "\n",
      "Iter 35500\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.5863], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 30 times\n",
      "\n",
      "Iter 36000\n",
      "Objective: tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.7449], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0031, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 36500\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.7449], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0025, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 37000\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.7449], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 31 times\n",
      "\n",
      "Iter 37500\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.9194], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 38000\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([1.9194], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 32 times\n",
      "\n",
      "Iter 38500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.1114], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0040, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 39000\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.1114], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 39500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.1114], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 33 times\n",
      "\n",
      "Iter 40000\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.3225], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0041, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 40500\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.3225], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0028, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 41000\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.3225], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 34 times\n",
      "\n",
      "Iter 41500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.5548], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0024, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 42000\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.5548], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 35 times\n",
      "\n",
      "Iter 42500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.8102], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0024, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 43000\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([2.8102], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 36 times\n",
      "\n",
      "Iter 43500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([3.0913], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 44000\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([3.0913], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 37 times\n",
      "\n",
      "Iter 44500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([3.4004], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 45000\n",
      "Objective: tensor(0.0047, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([3.4004], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 38 times\n",
      "\n",
      "Iter 45500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([3.7404], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0042, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 39 times\n",
      "\n",
      "Iter 46000\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([4.1145], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0035, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 46500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([4.1145], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 47000\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([4.1145], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0035, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 40 times\n",
      "\n",
      "Iter 47500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([4.5259], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 48000\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([4.5259], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0021, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 48500\n",
      "Objective: tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([4.5259], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0041, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 41 times\n",
      "\n",
      "Iter 49000\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([4.9785], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0024, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 49500\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([4.9785], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 50000\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([4.9785], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 42 times\n",
      "\n",
      "Iter 50500\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([5.4764], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0031, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 51000\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([5.4764], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0025, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 51500\n",
      "Objective: tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([5.4764], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 43 times\n",
      "\n",
      "Iter 52000\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([6.0240], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0030, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 52500\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([6.0240], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0034, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 44 times\n",
      "\n",
      "Iter 53000\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([6.6264], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0028, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 53500\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([6.6264], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0021, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 54000\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([6.6264], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 54500\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([6.6264], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0036, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 45 times\n",
      "\n",
      "Iter 55000\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([7.2890], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0026, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 55500\n",
      "Objective: tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([7.2890], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 46 times\n",
      "\n",
      "Iter 56000\n",
      "Objective: tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([8.0180], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 56500\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([8.0180], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 57000\n",
      "Objective: tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([8.0180], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0026, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 47 times\n",
      "\n",
      "Iter 57500\n",
      "Objective: tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([8.8197], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0024, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 58000\n",
      "Objective: tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([8.8197], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 58500\n",
      "Objective: tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([8.8197], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 48 times\n",
      "\n",
      "Iter 59000\n",
      "Objective: tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([9.7017], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0038, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 49 times\n",
      "\n",
      "Iter 59500\n",
      "Objective: tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([10.6719], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 60000\n",
      "Objective: tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([10.6719], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0026, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 60500\n",
      "Objective: tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([10.6719], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 61000\n",
      "Objective: tensor(0.0052, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([10.6719], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 50 times\n",
      "\n",
      "Iter 61500\n",
      "Objective: tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([11.7391], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0031, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 51 times\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 62000\n",
      "Objective: tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([12.9130], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0026, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 62500\n",
      "Objective: tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([12.9130], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 63000\n",
      "Objective: tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([12.9130], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 63500\n",
      "Objective: tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([12.9130], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 52 times\n",
      "\n",
      "Iter 64000\n",
      "Objective: tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([14.2043], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 53 times\n",
      "\n",
      "Iter 64500\n",
      "Objective: tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([15.6247], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0034, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 54 times\n",
      "\n",
      "Iter 65000\n",
      "Objective: tensor(0.0055, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([17.1872], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 65500\n",
      "Objective: tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([17.1872], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0029, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 55 times\n",
      "\n",
      "Iter 66000\n",
      "Objective: tensor(0.0056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([18.9059], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 66500\n",
      "Objective: tensor(0.0056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([18.9059], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0022, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 56 times\n",
      "\n",
      "Iter 67000\n",
      "Objective: tensor(0.0056, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([20.7965], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0028, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 57 times\n",
      "\n",
      "Iter 67500\n",
      "Objective: tensor(0.0057, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([22.8762], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0039, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 58 times\n",
      "\n",
      "Iter 68000\n",
      "Objective: tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([25.1638], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0032, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 68500\n",
      "Objective: tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([25.1638], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 69000\n",
      "Objective: tensor(0.0058, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([25.1638], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 59 times\n",
      "\n",
      "Iter 69500\n",
      "Objective: tensor(0.0059, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([27.6801], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 70000\n",
      "Objective: tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([27.6801], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0020, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 60 times\n",
      "\n",
      "Iter 70500\n",
      "Objective: tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([30.4482], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 71000\n",
      "Objective: tensor(0.0060, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([30.4482], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 61 times\n",
      "\n",
      "Iter 71500\n",
      "Objective: tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([33.4930], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0021, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 62 times\n",
      "\n",
      "Iter 72000\n",
      "Objective: tensor(0.0062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([36.8423], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 72500\n",
      "Objective: tensor(0.0062, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([36.8423], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0026, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 63 times\n",
      "\n",
      "Iter 73000\n",
      "Objective: tensor(0.0063, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([40.5265], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0033, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 64 times\n",
      "\n",
      "Iter 73500\n",
      "Objective: tensor(0.0063, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([44.5792], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0034, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 65 times\n",
      "\n",
      "Iter 74000\n",
      "Objective: tensor(0.0064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([49.0371], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 74500\n",
      "Objective: tensor(0.0064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([49.0371], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 75000\n",
      "Objective: tensor(0.0064, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([49.0371], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Reset 66 times\n",
      "\n",
      "Iter 75500\n",
      "Objective: tensor(0.0065, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([53.9408], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n",
      "Iter 76000\n",
      "Objective: tensor(0.0065, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "Penalty parameter: tensor([53.9408], device='cuda:0', dtype=torch.float64)\n",
      "Penalty: tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "# exact_penalty_with_pygranso(mu_rho=1.1, mu_eps=1e-5\n",
    "if __name__ == \"__main__\":\n",
    "    # NN hyperparams - width + depth are somewhat arbitrary and vary between papers\n",
    "    input_size = 2\n",
    "    hidden_size = 20\n",
    "    num_layers = 7\n",
    "    double_precision = torch.double\n",
    "\n",
    "    # Create PINN\n",
    "    torch.manual_seed(552720250)\n",
    "    model = PINN(input_size, hidden_size, num_layers).to(device=device, dtype=double_precision)\n",
    "    model.train()\n",
    "\n",
    "    # Tensors have fixed size and we need to modify in-place, so initialize with maximum possible size\n",
    "    max_iters = 200\n",
    "    error = torch.empty(max_iters, device=device, dtype=double_precision)\n",
    "\n",
    "    # # Functions for optimizer\n",
    "    # comb_fn = lambda model: user_fn(model, sample_points, boundary_points, usolb)\n",
    "    # halt_log_fn = lambda iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized, ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level: \\\n",
    "    #     evaluate(iteration, model, xv, tv, usol_tensor, error)\n",
    "\n",
    "#     # Pygranso Options\n",
    "#     opts = pygransoStruct()\n",
    "#     nvar = getNvarTorch(model.parameters())\n",
    "#     opts.x0 = nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "#     opts.torch_device = device\n",
    "#     opts.double_precision = True\n",
    "#     opts.print_level = 1\n",
    "#     opts.print_frequency = 10\n",
    "#     opts.disable_terminationcode_6 = True # Important for training NNs\n",
    "#     opts.maxit = max_iters\n",
    "#     opts.halt_log_fn = halt_log_fn   \n",
    "    \n",
    "    f_lambda = lambda model: f(model, sample_points)   \n",
    "    penalty_lambda = lambda model: penalty(model, boundary_points, boundary_usol=usolb)\n",
    "\n",
    "    exact_penalty_with_adam(\n",
    "        model,\n",
    "        mu_0=0.1,\n",
    "        mu_rho=1.1,\n",
    "        mu_eps=1e-5,\n",
    "        f_lambda=f_lambda,\n",
    "        penalty_lambda=penalty_lambda,\n",
    "        n_inner_iters=1000,\n",
    "        max_iters=100,\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-track",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, t = sample_points\n",
    "# xt = torch.cat((x, t), 1)\n",
    "# u = model(xt)\n",
    "# print(u)\n",
    "\n",
    "x, t = sample_points\n",
    "xt = torch.cat((x, t), 1)\n",
    "u = model(xt)\n",
    "\n",
    "# Calculate gradients of network\n",
    "u_t, u_x, u_xx = get_grads(u, x, t)\n",
    "\n",
    "# Minimize residual\n",
    "res = u_t + u * u_x - 0.01 / np.pi * u_xx\n",
    "objective = torch.norm(res)\n",
    "\n",
    "# res.min()\n",
    "objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-server",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nearby-domain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-complexity",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_pinn(model):\n",
    "    model.eval()\n",
    "\n",
    "    test_output = model(grid_points)\n",
    "    #     test_sample_outputs = model(sample_points)\n",
    "\n",
    "    # Plot predictions, GT, and error over the full range\n",
    "    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2,3, figsize=(18, 12))\n",
    "    outimg = test_output.cpu().detach().numpy()\n",
    "    outimg = np.reshape(outimg, (xgridsize, tgridsize))\n",
    "\n",
    "    global_min = np.min([np.min(outimg), np.min(usol_full), np.min(np.abs(outimg - usol_full))])\n",
    "    global_max = np.max([np.max(outimg), np.max(usol_full), np.max(np.abs(outimg - usol_full))])\n",
    "\n",
    "    global_max = max(abs(global_max), abs(global_min))\n",
    "    global_min = -global_max\n",
    "    #     global_min = -1\n",
    "    #     global_max = 1\n",
    "\n",
    "    ax1.set_title(\"Predicted outputs from PINN\")\n",
    "    ax1.set_xlabel(\"t\")\n",
    "    ax1.set_ylabel(\"x\")\n",
    "    ax1.set_box_aspect(1)\n",
    "    ax1.imshow(outimg, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax2.set_title(\"Ground truth solution from burgers_shock.mat\")\n",
    "    ax2.set_xlabel(\"t\")\n",
    "    ax2.set_ylabel(\"x\")\n",
    "    ax2.set_box_aspect(1)\n",
    "    ax2.imshow(usol_full, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax3.set_title(\"Difference\")\n",
    "    ax3.set_xlabel(\"t\")\n",
    "    ax3.set_ylabel(\"x\")\n",
    "    ax3.set_box_aspect(1)\n",
    "    ax3.imshow(usol_full - outimg, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    # Calculate gradients of network\n",
    "    testu_t, testu_x, testu_xx = get_grads(test_output, xv, tv)\n",
    "\n",
    "    testres = testu_t + torch.flatten(test_output) * testu_x - 0.01 / np.pi * testu_xx\n",
    "\n",
    "    test_ut_img = testu_t.cpu().detach().numpy()\n",
    "    test_ut_img = np.reshape(test_ut_img, (xgridsize, tgridsize))\n",
    "    test_ux_img = testu_x.cpu().detach().numpy()\n",
    "    test_ux_img = np.reshape(test_ux_img, (xgridsize, tgridsize))\n",
    "    test_res_img = testres.cpu().detach().numpy()\n",
    "    test_res_img = np.reshape(test_res_img, (xgridsize, tgridsize))\n",
    "\n",
    "    ax4.set_title(\"Predicted derivative w.r.t. t\")\n",
    "    ax4.set_xlabel(\"t\")\n",
    "    ax4.set_ylabel(\"x\")\n",
    "    ax4.set_box_aspect(1)\n",
    "    ax4.imshow(test_ut_img, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax5.set_title(\"Predicted derivative w.r.t. x\")\n",
    "    ax5.set_xlabel(\"t\")\n",
    "    ax5.set_ylabel(\"x\")\n",
    "    ax5.set_box_aspect(1)\n",
    "    ax5.imshow(test_ux_img, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax6.set_title(\"Predicted PDE residual\")\n",
    "    ax6.set_xlabel(\"t\")\n",
    "    ax6.set_ylabel(\"x\")\n",
    "    ax6.set_box_aspect(1)\n",
    "    ax6.imshow(test_res_img, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "#         # Plot L2 loss over full grid\n",
    "#         iter_range = np.arange(1, soln.iters+1)\n",
    "#         error = error.detach().cpu().numpy()\n",
    "#         plt.plot(iter_range, error[:soln.iters])\n",
    "#         plt.xlabel(\"Iteration\")\n",
    "#         plt.ylabel(\"Relative L2 loss\")\n",
    "#         plt.show()\n",
    "plot_pinn(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "decimal-blackberry",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtest_output\u001b[49m\u001b[38;5;241m.\u001b[39mmin(), test_output\u001b[38;5;241m.\u001b[39mmax())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_output' is not defined"
     ]
    }
   ],
   "source": [
    "print(test_output.min(), test_output.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-transcription",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bottom-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_output = model(grid_points)\n",
    "testu_t, testu_x, testu_xx = get_grads(test_output, xv, tv)\n",
    "testres = testu_t + torch.flatten(test_output) * testu_x - 0.01 / np.pi * testu_xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "adjacent-thailand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test res tensor(91.8254, device='cuda:0', dtype=torch.float64, grad_fn=<CopyBackwards>)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test res\", torch.norm(testres))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contemporary-boating",
   "metadata": {},
   "source": [
    "### Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "agreed-observer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0214, device='cuda:0', dtype=torch.float64, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def evaluate2(iteration, model, xv, tv, test_usol, error):\n",
    "    \"\"\"Difference\"\"\"\n",
    "    test_points = torch.stack((xv, tv)).transpose(0,1)\n",
    "    pred_usol = model(test_points)\n",
    "    L2_error = torch.norm(pred_usol.flatten() - test_usol) ** 2 / pred_usol.numel()\n",
    "    print(L2_error)\n",
    "\n",
    "evaluate2(0, model, xv, tv, usol_tensor, error)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hungarian-threshold",
   "metadata": {},
   "source": [
    "### Feasibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "expanded-python",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:33:25.477782Z",
     "start_time": "2025-04-21T03:33:25.475067Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1479, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "penalty(model, boundary_points, boundary_usol=usolb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "powered-illustration",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:33:25.482666Z",
     "start_time": "2025-04-21T03:33:25.478488Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0635, device='cuda:0', dtype=torch.float64, grad_fn=<NormBackward1>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l2_penalty(model, boundary_points, boundary_usol=usolb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greenhouse-uniform",
   "metadata": {},
   "source": [
    "### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "royal-amendment",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:33:25.877361Z",
     "start_time": "2025-04-21T03:33:25.483363Z"
    }
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "contrary-synthetic",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:33:25.986355Z",
     "start_time": "2025-04-21T03:33:25.878117Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Plot results\n",
    "# x = np.arange(1, len(train_acc)+1)\n",
    "\n",
    "# plt.plot(x, train_acc, label='Train set accuracy', marker='o')\n",
    "# plt.plot(x, test_acc, label='Test set accuracy', marker='s')\n",
    "\n",
    "# plt.xlabel('Outer Loop Iterations')\n",
    "# plt.ylabel('Accuracy (%)')\n",
    "# plt.title('Train vs Test Accuracy Over Time - EP w/ Adam (100 inner iterations)'.format(batch_size))\n",
    "\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "surprising-juvenile",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:33:25.990674Z",
     "start_time": "2025-04-21T03:33:25.988108Z"
    }
   },
   "outputs": [],
   "source": [
    "train_acc_1000 = train_acc.copy()\n",
    "test_acc_1000 = test_acc.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-cross",
   "metadata": {},
   "source": [
    "### 3000 inner epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "selected-howard",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:33:25.994940Z",
     "start_time": "2025-04-21T03:33:25.992539Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_acc = []\n",
    "# test_acc = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-solid",
   "metadata": {},
   "source": [
    "### Train Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "regional-difficulty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:40:53.337852Z",
     "start_time": "2025-04-21T03:40:53.291372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final acc = 97.75%\n"
     ]
    }
   ],
   "source": [
    "# model.eval()\n",
    "\n",
    "# logits = model(inputs)\n",
    "# _, predicted = torch.max(logits.data, 1)\n",
    "# correct = (predicted == labels).sum().item()\n",
    "# print(\"Final acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-syndicate",
   "metadata": {},
   "source": [
    "### Test Acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "grand-great",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:40:53.367457Z",
     "start_time": "2025-04-21T03:40:53.339855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: \n",
      " Accuracy: 67.6% \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "67.578125"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# val_loop(val_dataloader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "close-affair",
   "metadata": {},
   "source": [
    "### Feasibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "statutory-binary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:51:25.692699Z",
     "start_time": "2025-04-21T03:51:25.672923Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1091e-05, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# penalty(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "roman-navigator",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-21T03:51:52.809080Z",
     "start_time": "2025-04-21T03:51:52.795588Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.8434e-07, dtype=torch.float64, grad_fn=<LinalgVectorNormBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# l2_penalty(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-madrid",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (csci-5527-project)",
   "language": "python",
   "name": "csci-5527-project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
