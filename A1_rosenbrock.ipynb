{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5257bb27",
   "metadata": {},
   "source": [
    "# Rosenbrock\n",
    "\n",
    "Minimize 2-variable nonsmooth Rosenbrock function, subject to a simple bound constraint. Taken from: [GRANSO](http://www.timmitchell.com/software/GRANSO/) demo examples 1, 2, & 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeebfa4",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94952c",
   "metadata": {},
   "source": [
    "$$\\min_{x_1,x_2} w|x_1^2-x_2|+(1-x_1)^2,$$\n",
    "$$\\text{s.t. }c_1(x_1,x_2) = \\sqrt{2}x_1-1 \\leq 0, c_(x_1,x_2)=2x_2-1\\leq0,$$\n",
    "\n",
    "where $w$ is a constant (e.g., $w=8$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfdd50",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path."
   ]
  },
  {
   "cell_type": "code",
   "id": "90ed32f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T07:21:05.559279Z",
     "start_time": "2025-03-21T07:21:05.530498Z"
    }
   },
   "source": [
    "import time\n",
    "import torch\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ec80716b",
   "metadata": {},
   "source": [
    "## Function Set-Up\n",
    "\n",
    "Encode the optimization variables, and objective and constraint functions.\n",
    "\n",
    "Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm."
   ]
  },
  {
   "cell_type": "code",
   "id": "fb360e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T07:21:05.916716Z",
     "start_time": "2025-03-21T07:21:05.910765Z"
    }
   },
   "source": [
    "device = torch.device('cpu')\n",
    "# variables and corresponding dimensions.\n",
    "var_in = {\"x1\": [1], \"x2\": [1]}\n",
    "\n",
    "def comb_fn(X_struct):\n",
    "    x1 = X_struct.x1\n",
    "    x2 = X_struct.x2\n",
    "    \n",
    "    # objective function\n",
    "    f = (8 * abs(x1**2 - x2) + (1 - x1)**2)\n",
    "\n",
    "    # inequality constraint, matrix form\n",
    "    ci = pygransoStruct()\n",
    "    ci.c1 = (2**0.5)*x1-1  \n",
    "    ci.c2 = 2*x2-1 \n",
    "\n",
    "    # equality constraint \n",
    "    ce = None\n",
    "\n",
    "    return [f,ci,ce]"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "f0f55ace",
   "metadata": {},
   "source": [
    "## User Options\n",
    "Specify user-defined options for PyGRANSO"
   ]
  },
  {
   "cell_type": "code",
   "id": "f3a65b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T07:21:07.423600Z",
     "start_time": "2025-03-21T07:21:07.417611Z"
    }
   },
   "source": [
    "opts = pygransoStruct()\n",
    "# option for switching QP solver. We only have osqp as the only qp solver in current version. Default is osqp\n",
    "# opts.QPsolver = 'osqp'\n",
    "\n",
    "# set an intial point\n",
    "# All the user-provided data (vector/matrix/tensor) must be in torch tensor format. \n",
    "# As PyTorch tensor is single precision by default, one must explicitly set `dtype=torch.double`.\n",
    "# Also, please make sure the device of provided torch tensor is the same as opts.torch_device.\n",
    "opts.x0 = torch.ones((2,1), device=device, dtype=torch.double)\n",
    "opts.torch_device = device"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "8bca18c7",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "id": "632976b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-21T07:21:08.972908Z",
     "start_time": "2025-03-21T07:21:08.936618Z"
    }
   },
   "source": [
    "start = time.time()\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))\n",
    "print(soln.final.x)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/PyGRANSO/pygranso/private/tensor2vec.py\", line 149, in tensor2vec\n",
      "    [f,ci,ce] = combinedFunction(X)\n",
      "                ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/b_/m0xhq6xs3gx3hc0kzw7d8sw40000gn/T/ipykernel_38214/2678609881.py\", line 13, in comb_fn\n",
      "    print(\"Objective:\", f(x1, x2))\n",
      "                        ^^^^^^^^^\n",
      "TypeError: 'Tensor' object is not callable\n",
      "\n",
      "Please check the setting of opts.globalAD\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[0;31mSystemExit\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3587: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## PyGRANSO Restarting\n",
    "**(Optional)** The following example shows how to set various PyGRANSO options (such as simpler ASCII printing) and how to restart PyGRANSO"
   ],
   "id": "887df6e6020d827e"
  },
  {
   "cell_type": "code",
   "id": "69083bd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:02:08.599078Z",
     "start_time": "2025-03-20T21:02:08.549448Z"
    }
   },
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "# set an infeasible initial point\n",
    "opts.x0 = 5.5*torch.ones((2,1), device=device, dtype=torch.double)\n",
    "\n",
    "# By default PyGRANSO will print using extended ASCII characters to 'draw' table borders and some color prints. \n",
    "# If user wants to create a log txt file of the console output, please set opts.print_ascii = True\n",
    "opts.print_ascii = True\n",
    "\n",
    "# By default, PyGRANSO prints an info message about QP solvers, since\n",
    "# PyGRANSO can be used with any QP solver that has a quadprog-compatible\n",
    "# interface.  Let's disable this message since we've already seen it \n",
    "# hundreds of times and can now recite it from memory.  ;-)\n",
    "opts.quadprog_info_msg  = False\n",
    "\n",
    "# Try a very short run. \n",
    "opts.maxit = 10 # default is 1000\n",
    "\n",
    "# PyGRANSO's penalty parameter is on the *objective* function, thus\n",
    "# higher penalty parameter values favor objective minimization more\n",
    "# highly than attaining feasibility.  Let's set PyGRANSO to start off\n",
    "# with a higher initial value of the penalty parameter.  PyGRANSO will\n",
    "# automatically tune the penalty parameter to promote progress towards \n",
    "# feasibility.  PyGRANSO only adjusts the penalty parameter in a\n",
    "# monotonically decreasing fashion.\n",
    "opts.mu0 = 100  # default is 1\n",
    "\n",
    "# start main algorithm\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn, user_opts = opts)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================================================================================\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             | \n",
      "Version 1.2.0                                                                                                    | \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  | \n",
      "==================================================================================================================\n",
      "Problem specifications:                                                                                          | \n",
      " # of variables                     :   2                                                                        | \n",
      " # of inequality constraints        :   2                                                                        | \n",
      " # of equality constraints          :   0                                                                        | \n",
      "==================================================================================================================\n",
      "     | <--- Penalty Function --> |                | Total Violation | <--- Line Search ---> | <- Stationarity -> | \n",
      "Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   | \n",
      "=====|===========================|================|=================|=======================|====================|\n",
      "   0 | 100.0000 |  21970.9436508 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.770   | \n",
      "   1 | 34.86784 |  1621.39077134 |  42.9789783006 | 11.08181 |   -  | S  |    10 | 0.001953 |     1 | 546.6040   | \n",
      "   2 | 34.86784 |  1429.03706389 |  38.6988409867 | 8.927033 |   -  | S  |     3 | 1.500000 |     1 | 4.414697   | \n",
      "   3 | 34.86784 |  1238.07365179 |  32.7384682238 | 9.826182 |   -  | S  |     1 | 1.000000 |     1 | 0.745430   | \n",
      "   4 | 34.86784 |  851.235643149 |  22.8828528609 | 7.304786 |   -  | S  |     4 | 3.000000 |     1 | 0.903762   | \n",
      "   5 | 34.86784 |  836.926357951 |  21.9986280771 | 8.359523 |   -  | S  |     1 | 1.000000 |     1 | 0.747271   | \n",
      "   6 | 34.86784 |  470.930433368 |  12.2362942706 | 6.654114 |   -  | S  |     2 | 2.000000 |     1 | 0.456728   | \n",
      "   7 | 34.86784 |  430.739556238 |  10.9740250870 | 6.935341 |   -  | S  |     2 | 0.500000 |     1 | 0.518934   | \n",
      "   8 | 34.86784 |  406.232222855 |  10.6112593188 | 6.020007 |   -  | S  |     2 | 2.000000 |     1 | 0.118681   | \n",
      "   9 | 34.86784 |  337.354463419 |  8.59448838941 | 6.138663 |   -  | S  |     1 | 1.000000 |     1 | 0.398267   | \n",
      "  10 | 34.86784 |  327.703497800 |  8.39453176907 | 5.916441 |   -  | S  |     2 | 0.500000 |     1 | 0.146394   | \n",
      "==================================================================================================================\n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   | \n",
      "Optimization results:                                                                                            | \n",
      "==================================================================================================================\n",
      "   F |          |                |  8.39453176907 | 5.916441 |   -  |    |       |          |       |            | \n",
      "  MF |          |                |  8.80776635810 | 5.694219 |   -  |    |       |          |       |            | \n",
      "==================================================================================================================\n",
      "Iterations:              10                                                                                      | \n",
      "Function evaluations:    29                                                                                      | \n",
      "PyGRANSO termination code: 4 --- max iterations reached.                                                         | \n",
      "==================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "id": "167e4901",
   "metadata": {},
   "source": [
    "Let's restart PyGRANSO from the last iterate of the previous run"
   ]
  },
  {
   "cell_type": "code",
   "id": "53087da4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:02:08.745483Z",
     "start_time": "2025-03-20T21:02:08.600162Z"
    }
   },
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "# set the initial point and penalty parameter to their final values from the previous run\n",
    "opts.x0 = soln.final.x\n",
    "opts.mu0 = soln.final.mu\n",
    "opts.opt_tol = 1e-6\n",
    "\n",
    "# PREPARE TO RESTART PyGRANSO IN FULL-MEMORY MODE\n",
    "# Set the last BFGS inverse Hessian approximation as the initial\n",
    "# Hessian for the next run.  Generally this is a good thing to do, and\n",
    "# often it is necessary to retain this information when restarting (as\n",
    "# on difficult nonsmooth problems, PyGRANSO may not be able to restart\n",
    "# without it).  However, your mileage may vary.  In the test, with\n",
    "# the above settings, omitting H0 causes PyGRANSO to take an additional \n",
    "# 16 iterations to converge on this problem. \n",
    "opts.H0 = soln.H_final     # try running with this commented out\n",
    "\n",
    "# When restarting, soln.H_final may fail PyGRANSO's initial check to\n",
    "# assess whether or not the user-provided H0 is positive definite.  If\n",
    "# it fails this test, the test may be disabled by setting opts.checkH0 \n",
    "# to false.\n",
    "# opts.checkH0 = False       % Not needed for this example \n",
    "\n",
    "# If one desires to restart PyGRANSO as if it had never stopped (e.g.\n",
    "# to continue optimization after it hit its maxit limit), then one must\n",
    "# also disable scaling the initial BFGS inverse Hessian approximation \n",
    "# on the very first iterate. \n",
    "opts.scaleH0 = False\n",
    "\n",
    "# Restart PyGRANSO\n",
    "opts.maxit = 100 # increase maximum allowed iterations\n",
    "\n",
    "# Main algorithm\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn, user_opts = opts)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001B[0m\u001B[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001B[0m\u001B[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001B[0m\u001B[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001B[0m\u001B[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001B[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   2                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 34.86784 │  327.703497800 ║  8.39453176907 ║ 5.916441 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.202201   ║ \n",
      "   1 ║ 34.86784 │  220.220705305 ║  6.08782316530 ║ 2.819829 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 0.165431   ║ \n",
      "   2 ║ 34.86784 │  193.340169448 ║  5.37625777345 ║ 2.425212 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 1.752937   ║ \n",
      "   3 ║ 34.86784 │  173.060536667 ║  4.94636819609 ║ 0.768988 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.952490   ║ \n",
      "   4 ║ 12.15767 │  57.9818718970 ║  4.60056471498 ║ 1.431693 │   -  ║ S  │     5 │ 16.00000 ║     1 │ 0.418402   ║ \n",
      "   5 ║ 12.15767 │  55.5371382356 ║  4.50368580172 ║ 0.884778 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.039682   ║ \n",
      "   6 ║ 4.239116 │  15.0477752275 ║  3.50208882135 ║ 0.449461 │   -  ║ S  │     5 │ 16.00000 ║     1 │ 0.157303   ║ \n",
      "   7 ║ 4.239116 │  13.2574886485 ║  3.12741835513 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.061354   ║ \n",
      "   8 ║ 4.239116 │  12.2639538329 ║  2.89304523205 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.166141   ║ \n",
      "   9 ║ 4.239116 │  11.0487301528 ║  2.60637609406 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.675571   ║ \n",
      "  10 ║ 4.239116 │  9.00582510280 ║  2.12445837038 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.234553   ║ \n",
      "  11 ║ 4.239116 │  8.37641975382 ║  1.97598275080 ║ 0.000000 │   -  ║ S  │     3 │ 1.500000 ║     1 │ 0.448098   ║ \n",
      "  12 ║ 4.239116 │  7.71762747729 ║  1.82057480647 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.035718   ║ \n",
      "  13 ║ 4.239116 │  6.37278323183 ║  1.50332840411 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.351273   ║ \n",
      "  14 ║ 4.239116 │  6.35432141933 ║  1.49897329487 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.310033   ║ \n",
      "  15 ║ 4.239116 │  4.98050818675 ║  1.17489315918 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.024820   ║ \n",
      "  16 ║ 4.239116 │  4.62568994048 ║  1.09119215626 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.322096   ║ \n",
      "  17 ║ 4.239116 │  4.49095041264 ║  1.05940733761 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.023600   ║ \n",
      "  18 ║ 4.239116 │  4.17811552734 ║  0.98561013601 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.034100   ║ \n",
      "  19 ║ 4.239116 │  3.47365968746 ║  0.81943023706 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.200659   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  20 ║ 4.239116 │  3.32158707729 ║  0.78355657463 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.013850   ║ \n",
      "  21 ║ 4.239116 │  2.67224942680 ║  0.63037896003 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.242575   ║ \n",
      "  22 ║ 4.239116 │  2.22869552276 ║  0.52574537084 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.013722   ║ \n",
      "  23 ║ 4.239116 │  1.96028310744 ║  0.46242735212 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.103943   ║ \n",
      "  24 ║ 4.239116 │  1.76354332164 ║  0.41601678119 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.148533   ║ \n",
      "  25 ║ 4.239116 │  1.42843029939 ║  0.33696420610 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.010693   ║ \n",
      "  26 ║ 4.239116 │  1.27891308587 ║  0.30169335727 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.186900   ║ \n",
      "  27 ║ 4.239116 │  1.11990416618 ║  0.26418343158 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.016880   ║ \n",
      "  28 ║ 4.239116 │  0.94196945535 ║  0.22220894490 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.174203   ║ \n",
      "  29 ║ 4.239116 │  0.91887141089 ║  0.21676015666 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.004515   ║ \n",
      "  30 ║ 4.239116 │  0.64038348989 ║  0.15106534380 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.160221   ║ \n",
      "  31 ║ 4.239116 │  0.64006584539 ║  0.15099041202 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.076783   ║ \n",
      "  32 ║ 4.239116 │  0.56764548185 ║  0.13390657509 ║ 0.000000 │   -  ║ S  │     3 │ 4.000000 ║     1 │ 0.083673   ║ \n",
      "  33 ║ 4.239116 │  0.48432364061 ║  0.11425109865 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.008163   ║ \n",
      "  34 ║ 4.239116 │  0.40946047256 ║  0.09659100841 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.025022   ║ \n",
      "  35 ║ 4.239116 │  0.40374210825 ║  0.09524169033 ║ 0.001246 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.001384   ║ \n",
      "  36 ║ 2.781284 │  0.24290904413 ║  0.08733701893 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.001701   ║ \n",
      "  37 ║ 2.781284 │  0.24047452989 ║  0.08646169863 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 8.47e-04   ║ \n",
      "  38 ║ 2.781284 │  0.23948343058 ║  0.08610535266 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 6.15e-05   ║ \n",
      "  39 ║ 2.503156 │  0.21545651988 ║  0.08607396465 ║ 3.79e-05 │   -  ║ S  │     2 │ 2.000000 ║     2 │ 4.64e-05   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  40 ║ 2.252840 │  0.19384496426 ║  0.08604471164 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     2 │ 9.28e-06   ║ \n",
      "  41 ║ 2.252840 │  0.19333142148 ║  0.08581675813 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     3 │ 1.96e-17   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "Optimization results:                                                                                            ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.08581675813 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║  0.08578643763 ║ 8.95e-13 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.08581675813 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              41                                                                                      ║ \n",
      "Function evaluations:    85                                                                                      ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "6ef5310c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:02:08.750981Z",
     "start_time": "2025-03-20T21:02:08.747320Z"
    }
   },
   "source": [
    "soln.final.x"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7071],\n",
       "        [0.5000]], dtype=torch.float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "markdown",
   "id": "f1d015a6",
   "metadata": {},
   "source": [
    "## Results Logs\n",
    "\n",
    "**(Optional)** opts below shows the importance of using an initial point that is neither near\n",
    "nor on a nonsmooth manifold, that is, the functions \n",
    "(objective and constraints) should be smooth at and *about* \n",
    "the initial point."
   ]
  },
  {
   "cell_type": "code",
   "id": "a6c968a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:02:08.755600Z",
     "start_time": "2025-03-20T21:02:08.751750Z"
    }
   },
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "# Set a randomly generated starting point.  In theory, with probability \n",
    "# one, a randomly selected point will not be on a nonsmooth manifold.\n",
    "opts.x0 = torch.randn((2,1), device=device, dtype=torch.double)   # randomly generated is okay\n",
    "opts.maxit = 100  # we'll use this value of maxit later\n",
    "opts.opt_tol = 1e-6\n",
    "\n",
    "# However, (0,0) or (1,1) are on the nonsmooth manifold and if PyGRANSO\n",
    "# is started at either of them, it will break down on the first\n",
    "# iteration.  This example highlights that it is imperative to start\n",
    "# PyGRANSO at a point where the functions are smooth.\n",
    "\n",
    "# Uncomment either of the following two lines to try starting PyGRANSO\n",
    "# from (0,0) or (1,1), where the functions are not differentiable. \n",
    "    \n",
    "# opts.x0 = torch.ones((2,1), device=device, dtype=torch.double)     # uncomment this line to try this point\n",
    "# opts.x0 = torch.zeros((2,1), device=device, dtype=torch.double)    # uncomment this line to try this point\n",
    "\n",
    "# Uncomment the following two lines to try starting PyGRANSO from a\n",
    "# uniformly perturbed version of (1,1).  pert_level needs to be at\n",
    "# least 1e-3 or so to get consistently reliable optimization quality.\n",
    "\n",
    "# pert_level = 1e-3\n",
    "# opts.x0 = (torch.ones((2,1)) + pert_level * (torch.randn((2,1)) - 0.5)).to(device=device, dtype=torch.double)"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "bcf39d83",
   "metadata": {},
   "source": [
    "The opts below show how to use opts.halt_log_fn to create a history of iterates\n",
    "\n",
    "NOTE: NO NEED TO CHANGE ANYTHING BELOW"
   ]
  },
  {
   "cell_type": "code",
   "id": "42b9acec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:02:08.855026Z",
     "start_time": "2025-03-20T21:02:08.756598Z"
    }
   },
   "source": [
    "# SETUP THE LOGGING FEATURES\n",
    "    \n",
    "# Set up PyGRANSO's logging functions; pass opts.maxit to it so that\n",
    "# storage can be preallocated for efficiency.\n",
    "\n",
    "class HaltLog:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def haltLog(self, iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized,\n",
    "                ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level):\n",
    "\n",
    "        # DON'T CHANGE THIS\n",
    "        # increment the index/count \n",
    "        self.index += 1                  \n",
    "\n",
    "        # EXAMPLE:\n",
    "        # store history of x iterates in a preallocated cell array\n",
    "        self.x_iterates.append(x)\n",
    "        self.f.append(penaltyfn_parts.f)\n",
    "        self.tv.append(penaltyfn_parts.tv)\n",
    "\n",
    "        # keep this false unless you want to implement a custom termination\n",
    "        # condition\n",
    "        halt = False\n",
    "        return halt\n",
    "    \n",
    "    # Once PyGRANSO has run, you may call this function to get retreive all\n",
    "    # the logging data stored in the shared variables, which is populated \n",
    "    # by haltLog being called on every iteration of PyGRANSO.\n",
    "    def getLog(self):\n",
    "        # EXAMPLE\n",
    "        # return x_iterates, trimmed to correct size \n",
    "        log = pygransoStruct()\n",
    "        log.x   = self.x_iterates[0:self.index]\n",
    "        log.f   = self.f[0:self.index]\n",
    "        log.tv  = self.tv[0:self.index]\n",
    "        return log\n",
    "\n",
    "    def makeHaltLogFunctions(self,maxit):\n",
    "        # don't change these lambda functions \n",
    "        halt_log_fn = lambda iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized, ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level: self.haltLog(iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized, ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level)\n",
    "                \n",
    "        get_log_fn = lambda : self.getLog()\n",
    "\n",
    "        # Make your shared variables here to store PyGRANSO history data\n",
    "        # EXAMPLE - store history of iterates x_0,x_1,...,x_k\n",
    "        self.index       = 0\n",
    "        self.x_iterates  = []\n",
    "        self.f           = []\n",
    "        self.tv          = []\n",
    "\n",
    "        # Only modify the body of logIterate(), not its name or arguments.\n",
    "        # Store whatever data you wish from the current PyGRANSO iteration info,\n",
    "        # given by the input arguments, into shared variables of\n",
    "        # makeHaltLogFunctions, so that this data can be retrieved after PyGRANSO\n",
    "        # has been terminated.\n",
    "        # \n",
    "        # DESCRIPTION OF INPUT ARGUMENTS\n",
    "        #   iter                current iteration number\n",
    "        #   x                   current iterate x \n",
    "        #   penaltyfn_parts     struct containing the following\n",
    "        #       OBJECTIVE AND CONSTRAINTS VALUES\n",
    "        #       .f              objective value at x\n",
    "        #       .f_grad         objective gradient at x\n",
    "        #       .ci             inequality constraint at x\n",
    "        #       .ci_grad        inequality gradient at x\n",
    "        #       .ce             equality constraint at x\n",
    "        #       .ce_grad        equality gradient at x\n",
    "        #       TOTAL VIOLATION VALUES (inf norm, for determining feasibiliy)\n",
    "        #       .tvi            total violation of inequality constraints at x\n",
    "        #       .tve            total violation of equality constraints at x\n",
    "        #       .tv             total violation of all constraints at x\n",
    "        #       TOTAL VIOLATION VALUES (one norm, for L1 penalty function)\n",
    "        #       .tvi_l1         total violation of inequality constraints at x\n",
    "        #       .tvi_l1_grad    its gradient\n",
    "        #       .tve_l1         total violation of equality constraints at x\n",
    "        #       .tve_l1_grad    its gradient\n",
    "        #       .tv_l1          total violation of all constraints at x\n",
    "        #       .tv_l1_grad     its gradient\n",
    "        #       PENALTY FUNCTION VALUES \n",
    "        #       .p              penalty function value at x\n",
    "        #       .p_grad         penalty function gradient at x\n",
    "        #       .mu             current value of the penalty parameter\n",
    "        #       .feasible_to_tol logical indicating whether x is feasible\n",
    "        #   d                   search direction\n",
    "        #   get_BFGS_state_fn   function handle to get the (L)BFGS state data     \n",
    "        #                       FULL MEMORY: \n",
    "        #                       - returns BFGS inverse Hessian approximation \n",
    "        #                       LIMITED MEMORY:\n",
    "        #                       - returns a struct with current L-BFGS state:\n",
    "        #                           .S          matrix of the BFGS s vectors\n",
    "        #                           .Y          matrix of the BFGS y vectors\n",
    "        #                           .rho        row vector of the 1/sty values\n",
    "        #                           .gamma      H0 scaling factor\n",
    "        #   H_regularized       regularized version of H \n",
    "        #                       [] if no regularization was applied to H\n",
    "        #   fn_evals            number of function evaluations incurred during\n",
    "        #                       this iteration\n",
    "        #   alpha               size of accepted size\n",
    "        #   n_gradients         number of previous gradients used for computing\n",
    "        #                       the termination QP\n",
    "        #   stat_vec            stationarity measure vector                 \n",
    "        #   stat_val            approximate value of stationarity:\n",
    "        #                           norm(stat_vec)\n",
    "        #                       gradients (result of termination QP)\n",
    "        #   fallback_level      number of strategy needed for a successful step\n",
    "        #                       to be taken.  See bfgssqpOptionsAdvanced.\n",
    "        #\n",
    "        # OUTPUT ARGUMENT\n",
    "        #   halt                set this to true if you wish optimization to \n",
    "        #                       be halted at the current iterate.  This can be \n",
    "        #                       used to create a custom termination condition,\n",
    "        return [halt_log_fn, get_log_fn]\n",
    "\n",
    "mHLF_obj = HaltLog()\n",
    "[halt_log_fn, get_log_fn] = mHLF_obj.makeHaltLogFunctions(opts.maxit)\n",
    "\n",
    "#  Set PyGRANSO's logging function in opts\n",
    "opts.halt_log_fn = halt_log_fn\n",
    "\n",
    "# Main algorithm with logging enabled.\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn, user_opts = opts)\n",
    "\n",
    "# GET THE HISTORY OF ITERATES\n",
    "# Even if an error is thrown, the log generated until the error can be\n",
    "# obtained by calling get_log_fn()\n",
    "log = get_log_fn()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001B[0m\u001B[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001B[0m\u001B[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001B[0m\u001B[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001B[0m\u001B[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001B[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   2                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  15.3383252558 ║  15.3383252558 ║ 0.000000 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 12.64938   ║ \n",
      "   1 ║ 1.000000 │  9.32688175502 ║  9.30737523799 ║ 0.139666 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 13.87045   ║ \n",
      "   2 ║ 1.000000 │  2.21845842491 ║  2.21845842491 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.698022   ║ \n",
      "   3 ║ 1.000000 │  1.30816526739 ║  1.30816526739 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.789089   ║ \n",
      "   4 ║ 1.000000 │  1.07327377855 ║  1.07327377855 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.391260   ║ \n",
      "   5 ║ 1.000000 │  0.78634054467 ║  0.78634054467 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 1.320496   ║ \n",
      "   6 ║ 1.000000 │  0.70155869171 ║  0.70155869171 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.139729   ║ \n",
      "   7 ║ 1.000000 │  0.67869644419 ║  0.67869644419 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.009886   ║ \n",
      "   8 ║ 1.000000 │  0.50872866492 ║  0.50872866492 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 0.023662   ║ \n",
      "   9 ║ 1.000000 │  0.44563282726 ║  0.44563282726 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.160895   ║ \n",
      "  10 ║ 1.000000 │  0.41164147770 ║  0.41164147770 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.108267   ║ \n",
      "  11 ║ 1.000000 │  0.37750419859 ║  0.37750419859 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.042025   ║ \n",
      "  12 ║ 1.000000 │  0.37634231043 ║  0.37634231043 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.166613   ║ \n",
      "  13 ║ 1.000000 │  0.33966632181 ║  0.33966632181 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.020057   ║ \n",
      "  14 ║ 1.000000 │  0.32960885904 ║  0.32960885904 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.004722   ║ \n",
      "  15 ║ 1.000000 │  0.24701777394 ║  0.24701777394 ║ 0.000000 │   -  ║ S  │     6 │ 32.00000 ║     1 │ 0.083222   ║ \n",
      "  16 ║ 1.000000 │  0.22906607627 ║  0.22906607627 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.094803   ║ \n",
      "  17 ║ 1.000000 │  0.19797868808 ║  0.19797868808 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.033375   ║ \n",
      "  18 ║ 1.000000 │  0.18339594675 ║  0.18339594675 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.138241   ║ \n",
      "  19 ║ 1.000000 │  0.17675109609 ║  0.17675109609 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.006105   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  20 ║ 1.000000 │  0.11090474777 ║  0.11090474777 ║ 0.000000 │   -  ║ S  │     4 │ 8.000000 ║     1 │ 0.053272   ║ \n",
      "  21 ║ 1.000000 │  0.10757601853 ║  0.10757601853 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.033847   ║ \n",
      "  22 ║ 1.000000 │  0.09570569775 ║  0.09570569775 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 5.05e-04   ║ \n",
      "  23 ║ 1.000000 │  0.08863956834 ║  0.08863905975 ║ 7.13e-04 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 7.98e-04   ║ \n",
      "  24 ║ 1.000000 │  0.08612621689 ║  0.08612621689 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 5.07e-04   ║ \n",
      "  25 ║ 1.000000 │  0.08584022162 ║  0.08584022162 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     2 │ 3.90e-05   ║ \n",
      "  26 ║ 1.000000 │  0.08580653806 ║  0.08580653806 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     3 │ 3.37e-05   ║ \n",
      "  27 ║ 1.000000 │  0.08580086188 ║  0.08580086188 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     4 │ 0.000000   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "Optimization results:                                                                                            ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.08580086188 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║  0.08580086188 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.08580086188 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              27                                                                                      ║ \n",
      "Function evaluations:    65                                                                                      ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "id": "557f5a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:02:08.859647Z",
     "start_time": "2025-03-20T21:02:08.856169Z"
    }
   },
   "source": [
    "print(log.f[0:3])\n",
    "print(log.x[0:3])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15.338325255812942, 9.30737523799293, 2.2184584249066925]\n",
      "[tensor([[-0.5861],\n",
      "        [-1.2593]], dtype=torch.float64), tensor([[ 0.8059],\n",
      "        [-0.5093]], dtype=torch.float64), tensor([[-0.0906],\n",
      "        [ 0.1368]], dtype=torch.float64)]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "fc946bc6",
   "metadata": {},
   "source": [
    "## LFBGS Restarting\n",
    " \n",
    "**(Optional)**\n",
    "\n",
    " (Note that this example problem only has two variables!)\n",
    " \n",
    " If PyGRANSO runs in limited-memory mode, that is, if \n",
    " opts.limited_mem_size > 0, then PyGRANSO's restart procedure is \n",
    " slightly different from the BFGS restarting, as soln.H_final will instead contain the most \n",
    " current L-BFGS state, not a full inverse Hessian approximation.  \n",
    " \n",
    " Instead the BFGS standard procedure, users should do the following: \n",
    " 1) If you set a specific H0, you will need to set opts.H0 to whatever\n",
    "    you used previously.  By default, PyGRANSO uses the identity for H0.\n",
    "    \n",
    " 2) Warm-start PyGRANSO with the most recent L-BFGS data by setting:\n",
    "    opts.limited_mem_warm_start = soln.H_final;\n",
    "    \n",
    " NOTE: how to set opts.scaleH0 so that PyGRANSO will be restarted as if\n",
    " it had never terminated depends on the previously used values of \n",
    " opts.scaleH0 and opts.limited_mem_fixed_scaling. "
   ]
  },
  {
   "cell_type": "code",
   "id": "8f78321f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:02:08.920378Z",
     "start_time": "2025-03-20T21:02:08.860567Z"
    }
   },
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "# set an infeasible initial point\n",
    "opts.x0 = 5.5*torch.ones((2,1), device=device, dtype=torch.double)\n",
    "\n",
    "opts.print_ascii = True\n",
    "opts.quadprog_info_msg  = False\n",
    "opts.maxit = 10 # default is 1000\n",
    "opts.mu0 = 100  # default is 1\n",
    "opts.print_frequency = 2\n",
    "\n",
    "\n",
    "# By default, PyGRANSO uses full-memory BFGS updating.  For nonsmooth\n",
    "# problems, full-memory BFGS is generally recommended.  However, if\n",
    "# this is not feasible, one may optionally enable limited-memory BFGS\n",
    "# updating by setting opts.limited_mem_size to a positive integer\n",
    "# (significantly) less than the number of variables.\n",
    "opts.limited_mem_size = 1\n",
    "\n",
    "# start main algorithm\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn, user_opts = opts)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "==================================================================================================================\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             | \n",
      "Version 1.2.0                                                                                                    | \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  | \n",
      "==================================================================================================================\n",
      "Problem specifications:                                                                                          | \n",
      " # of variables                     :   2                                                                        | \n",
      " # of inequality constraints        :   2                                                                        | \n",
      " # of equality constraints          :   0                                                                        | \n",
      "==================================================================================================================\n",
      "Limited-memory mode enabled with size = 1.                                                                       | \n",
      "NOTE: limited-memory mode is generally NOT                                                                       | \n",
      "recommended for nonsmooth problems.                                                                              | \n",
      "==================================================================================================================\n",
      "     | <--- Penalty Function --> |                | Total Violation | <--- Line Search ---> | <- Stationarity -> | \n",
      "Iter |    Mu    |      Value     |    Objective   |   Ineq   |  Eq  | SD | Evals |     t    | Grads |    Value   | \n",
      "=====|===========================|================|=================|=======================|====================|\n",
      "   0 | 100.0000 |  21970.9436508 |  218.250000000 | 10.00000 |   -  | -  |     1 | 0.000000 |     1 | 9732.770   | \n",
      "   2 | 34.86784 |  1429.03706389 |  38.6988409867 | 8.927033 |   -  | S  |     3 | 1.500000 |     1 | 4.414697   | \n",
      "   4 | 34.86784 |  833.341725016 |  22.3574648593 | 7.333834 |   -  | S  |     4 | 3.000000 |     1 | 0.905749   | \n",
      "   6 | 34.86784 |  426.646627702 |  10.9570254803 | 6.678231 |   -  | S  |     2 | 2.000000 |     1 | 0.453199   | \n",
      "   8 | 34.86784 |  350.569424144 |  8.86595263554 | 6.436829 |   -  | S  |     1 | 1.000000 |     1 | 0.118772   | \n",
      "  10 | 12.15767 |  88.2515364601 |  6.30885429085 | 3.398617 |   -  | S  |     5 | 0.062500 |     1 | 3.234259   | \n",
      "==================================================================================================================\n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   | \n",
      "Optimization results:                                                                                            | \n",
      "==================================================================================================================\n",
      "   F |          |                |  6.30885429085 | 3.398617 |   -  |    |       |          |       |            | \n",
      "  MF |          |                |  7.49249613373 | 3.064707 |   -  |    |       |          |       |            | \n",
      "==================================================================================================================\n",
      "Iterations:              10                                                                                      | \n",
      "Function evaluations:    32                                                                                      | \n",
      "PyGRANSO termination code: 4 --- max iterations reached.                                                         | \n",
      "==================================================================================================================\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "id": "e363ffda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T21:02:09.165621Z",
     "start_time": "2025-03-20T21:02:08.921366Z"
    }
   },
   "source": [
    "# Restart\n",
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "# set the initial point and penalty parameter to their final values from the previous run\n",
    "opts.x0 = soln.final.x\n",
    "opts.mu0 = soln.final.mu\n",
    "opts.limited_mem_size = 1\n",
    "opts.quadprog_info_msg  = False\n",
    "opts.print_frequency = 2\n",
    "\n",
    "opts.limited_mem_warm_start = soln.H_final\n",
    "opts.scaleH0 = False\n",
    "\n",
    "# In contrast to full-memory BFGS updating, limited-memory BFGS\n",
    "# permits that H0 can be scaled on every iteration.  By default,\n",
    "# PyGRANSO will reuse the scaling parameter that is calculated on the\n",
    "# very first iteration for all subsequent iterations as well.  Set\n",
    "# this option to false to force PyGRANSO to calculate a new scaling\n",
    "# parameter on every iteration.  Note that opts.scaleH0 has no effect\n",
    "# when opts.limited_mem_fixed_scaling is set to true.\n",
    "opts.limited_mem_fixed_scaling = False\n",
    "\n",
    "# Restart PyGRANSO\n",
    "opts.maxit = 100 # increase maximum allowed iterations\n",
    "\n",
    "# Main algorithm\n",
    "soln = pygranso(var_spec = var_in,combined_fn = comb_fn, user_opts = opts)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2                                                                        ║ \n",
      " # of inequality constraints        :   2                                                                        ║ \n",
      " # of equality constraints          :   0                                                                        ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "\u001B[33mLimited-memory mode enabled with size = 1.                                                                      \u001B[0m ║ \n",
      "\u001B[33mNOTE: limited-memory mode is generally NOT                                                                      \u001B[0m ║ \n",
      "\u001B[33mrecommended for nonsmooth problems.                                                                             \u001B[0m ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 12.15767 │  88.2515364601 ║  6.30885429085 ║ 3.398617 │   -  ║ -  │     1 │ 0.000000 ║     1 │ 0.427097   ║ \n",
      "   2 ║ 12.15767 │  72.9315951563 ║  5.99593026235 ║ 0.187299 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 3.792218   ║ \n",
      "   4 ║ 4.239116 │  16.4386007562 ║  3.76683697716 ║ 0.685961 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.069200   ║ \n",
      "   6 ║ 1.478088 │  4.74040612543 ║  3.20688126915 ║ 0.018774 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.254654   ║ \n",
      "   8 ║ 1.478088 │  4.36179382441 ║  2.95096973685 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.027380   ║ \n",
      "  10 ║ 1.478088 │  4.23804406958 ║  2.86724689342 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.016015   ║ \n",
      "  12 ║ 1.478088 │  3.68211528557 ║  2.49113351358 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.030799   ║ \n",
      "  14 ║ 1.478088 │  3.39461958328 ║  2.29662841978 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.014687   ║ \n",
      "  16 ║ 1.478088 │  3.22988435286 ║  2.18517687046 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.028480   ║ \n",
      "  18 ║ 1.478088 │  2.83868987963 ║  1.92051441776 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.444590   ║ \n",
      "  20 ║ 1.478088 │  2.24377588877 ║  1.51802561299 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.182677   ║ \n",
      "  22 ║ 1.478088 │  2.12391860334 ║  1.43693621806 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.021234   ║ \n",
      "  24 ║ 1.478088 │  1.80779066460 ║  1.22305999700 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.112256   ║ \n",
      "  26 ║ 1.478088 │  1.27427000802 ║  0.86210682614 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.058097   ║ \n",
      "  28 ║ 1.478088 │  1.10724967804 ║  0.74910929369 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.031218   ║ \n",
      "  30 ║ 1.478088 │  0.87905183028 ║  0.59472213789 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.174935   ║ \n",
      "  32 ║ 1.478088 │  0.85147472053 ║  0.57606485614 ║ 0.000000 │   -  ║ S  │     2 │ 2.000000 ║     1 │ 0.006661   ║ \n",
      "  34 ║ 1.478088 │  0.71579669725 ║  0.48427194782 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.230018   ║ \n",
      "  36 ║ 1.478088 │  0.49637953458 ║  0.33582536074 ║ 0.000000 │   -  ║ S  │     4 │ 0.125000 ║     1 │ 0.017238   ║ \n",
      "  38 ║ 1.478088 │  0.48044101829 ║  0.32504216439 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.142238   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║   Ineq   │  Eq  ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "  40 ║ 1.478088 │  0.38918107239 ║  0.26330028722 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.007377   ║ \n",
      "  42 ║ 1.478088 │  0.23493868677 ║  0.15894766754 ║ 0.000000 │   -  ║ S  │     3 │ 0.250000 ║     1 │ 0.104204   ║ \n",
      "  44 ║ 1.478088 │  0.22022420326 ║  0.14899259004 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.002284   ║ \n",
      "  46 ║ 1.478088 │  0.19395992247 ║  0.13122350217 ║ 0.000000 │   -  ║ S  │     2 │ 0.500000 ║     1 │ 0.183822   ║ \n",
      "  48 ║ 1.478088 │  0.16796235919 ║  0.11363486191 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.004435   ║ \n",
      "  50 ║ 1.478088 │  0.15224302623 ║  0.10299995395 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 0.015673   ║ \n",
      "  52 ║ 1.478088 │  0.12882550247 ║  0.08715683832 ║ 0.000000 │   -  ║ S  │     7 │ 0.015625 ║     1 │ 0.072146   ║ \n",
      "  54 ║ 1.478088 │  0.12731597120 ║  0.08613556558 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     1 │ 4.06e-05   ║ \n",
      "  56 ║ 1.478088 │  0.12686712921 ║  0.08583190173 ║ 0.000000 │   -  ║ S  │     1 │ 1.000000 ║     3 │ 5.52e-19   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "Optimization results:                                                                                            ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  0.08583190173 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "   B ║          │                ║  0.08583190173 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  0.08583190173 ║ 0.000000 │   -  ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              56                                                                                      ║ \n",
      "Function evaluations:    108                                                                                     ║ \n",
      "PyGRANSO termination code: 0 --- converged to stationarity and feasibility tolerances.                           ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n"
     ]
    }
   ],
   "execution_count": 24
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
