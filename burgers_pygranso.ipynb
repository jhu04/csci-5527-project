{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T14:25:43.361260Z",
     "start_time": "2025-05-10T14:25:41.971151Z"
    }
   },
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct\n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T14:25:43.367366Z",
     "start_time": "2025-05-10T14:25:43.364227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Physics-informed neural network - a straightforward MLP with tanh activations\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.linear_in = nn.Linear(input_size, hidden_size)\n",
    "        self.linear_hidden = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for i in range(num_layers - 1)])\n",
    "        self.linear_out = nn.Linear(hidden_size, 1)\n",
    "        self.activ = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear_in(x)\n",
    "        x = self.activ(x)\n",
    "        for l in self.linear_hidden:\n",
    "            x = l(x)\n",
    "            x = self.activ(x)\n",
    "        out = self.linear_out(x)\n",
    "        return out\n",
    "\n",
    "# Helper function to extract gradients of the NN outputs\n",
    "def get_grads(u, x, t):\n",
    "    u_t = torch.autograd.grad(\n",
    "        u, t, \n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    u_x = torch.autograd.grad(\n",
    "        u, x,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    u_xx = torch.autograd.grad(\n",
    "        u_x, x,\n",
    "        grad_outputs=torch.ones_like(u_x),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "    return u_t, u_x, u_xx"
   ],
   "id": "5e478c4f701958d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T14:25:43.369817Z",
     "start_time": "2025-05-10T14:25:43.367828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# User function specifying objective and constraints - required by PyGRANSO\n",
    "def user_fn(model, sample_points, boundary_points, boundary_usol):\n",
    "    # Forward pass for sample points\n",
    "    x, t = sample_points\n",
    "    xt = torch.cat((x, t), 1)\n",
    "    u = model(xt)\n",
    "\n",
    "    # Calculate gradients of network\n",
    "    u_t, u_x, u_xx = get_grads(u, x, t)\n",
    "\n",
    "    # Minimize residual\n",
    "    res = u_t + u * u_x - 0.01 / np.pi * u_xx\n",
    "    f = torch.sum(res ** 2)\n",
    "\n",
    "    # No inequality constraints\n",
    "    ci = None\n",
    "\n",
    "    # Equality constraint on boundary points\n",
    "    ce = pygransoStruct()\n",
    "    xb, tb = boundary_points\n",
    "    xtb = torch.cat((xb, tb), 1)\n",
    "    ub = model(xtb)\n",
    "\n",
    "    ce.c1 = ub - boundary_usol\n",
    "\n",
    "    return [f,ci,ce]"
   ],
   "id": "61b41b32e33ff79f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T20:49:42.769745Z",
     "start_time": "2025-05-10T20:48:58.819611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluates the relative L2 error over all grid points\n",
    "# Notably, this is NOT what the PINN is minimizing--it only has access to boundary points\n",
    "def evaluate(iteration, model, xv, tv, test_usol, error):\n",
    "    test_points = torch.stack((xv, tv)).transpose(0,1)\n",
    "    pred_usol = model(test_points)\n",
    "    L2_error = torch.sqrt(torch.sum((pred_usol - test_usol) ** 2) / torch.sum(test_usol ** 2))\n",
    "    error[iteration-1] = L2_error.cpu().detach().item()\n",
    "\n",
    "    # Save intermediate results (NN outputs + PDE residuals) as images\n",
    "    if iteration % 25 == 0:\n",
    "        outimg = pred_usol.cpu().detach().numpy()\n",
    "        outimg = np.reshape(outimg, (xgridsize, tgridsize))\n",
    "        plt.imsave(\"output_imgs/predicted_\"+str(iteration)+\".png\", outimg, origin='upper')\n",
    "        plt.close()\n",
    "        evalu_t, evalu_x, evalu_xx = get_grads(pred_usol, xv, tv)\n",
    "        evalres = evalu_t + torch.flatten(pred_usol) * evalu_x - 0.01 / np.pi * evalu_xx\n",
    "        outimg = evalres.cpu().detach().numpy()\n",
    "        outimg = np.reshape(outimg, (xgridsize, tgridsize))\n",
    "        plt.imsave(\"output_imgs/pderesidual_\"+str(iteration)+\".png\", outimg, vmin=-3, vmax=3, origin='upper')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "    # double_precision = torch.double\n",
    "    double_precision = torch.float\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # NN hyperparams - width + depth are somewhat arbitrary and vary between papers\n",
    "    input_size = 2\n",
    "    hidden_size = 20\n",
    "    num_layers = 7\n",
    "\n",
    "    data = scipy.io.loadmat('./data/burgers_shock.mat')\n",
    "\n",
    "    # Create PINN\n",
    "    model = PINN(input_size, hidden_size, num_layers).to(device=device, dtype=double_precision)\n",
    "    model.train()\n",
    "\n",
    "    # Get boundary points along three sides (x = -1, x = 1, t = 0)\n",
    "    tb_x = data['t']\n",
    "    xb_t = data['x']\n",
    "    xb_xlow = np.full_like(tb_x, data['x'][0])\n",
    "    xb_xhigh = np.full_like(tb_x, data['x'][-1])\n",
    "    tb_tlow = np.full_like(xb_t, data['t'][0])\n",
    "\n",
    "    usol_xlow = data['usol'][0,:,None]\n",
    "    usol_xhigh = data['usol'][-1,:,None]\n",
    "    usol_tlow = data['usol'][:,0,None]\n",
    "\n",
    "    xb = np.vstack((xb_xlow, xb_xhigh, xb_t))\n",
    "    tb = np.vstack((tb_x, tb_x, tb_tlow))\n",
    "    usolb = np.vstack((usol_xlow, usol_xhigh, usol_tlow))\n",
    "\n",
    "    xb = torch.Tensor(xb).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    tb = torch.Tensor(tb).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    usolb = torch.Tensor(usolb).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    boundary_points = (xb, tb)\n",
    "\n",
    "    # Ground-truth data - used for testing/evaluation\n",
    "    usol_full = data['usol']\n",
    "    usol_tensor = usol_full.flatten()\n",
    "    usol_tensor = torch.Tensor(usol_tensor).to(device=device, dtype=double_precision)\n",
    "\n",
    "    # Sample points. Following Dual-Cone Gradient Descent, 10x as many sample points as boundary points\n",
    "    n_samples = 4560\n",
    "    xs = -1 + 2 * np.random.rand(n_samples, 1)\n",
    "    ts = np.random.rand(n_samples, 1)\n",
    "\n",
    "    xs = torch.Tensor(xs).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    ts = torch.Tensor(ts).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    sample_points = (xs, ts)\n",
    "\n",
    "    # Create grid inputs for visualization, comparison to GT\n",
    "    xgridsize = 256\n",
    "    tgridsize = 100\n",
    "    tv, xv = np.meshgrid(data['t'], data['x'])\n",
    "    tv = torch.Tensor(tv.flatten()).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    xv = torch.Tensor(xv.flatten()).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    grid_points = torch.stack((xv, tv)).transpose(0,1)\n",
    "\n",
    "    # Tensors have fixed size and we need to modify in-place, so initialize with maximum possible size\n",
    "    max_iters = 200\n",
    "    error = torch.empty(max_iters, device=device, dtype=double_precision)\n",
    "\n",
    "    # Functions for optimizer\n",
    "    comb_fn = lambda model: user_fn(model, sample_points, boundary_points, usolb)\n",
    "    halt_log_fn = lambda iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized, ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level: \\\n",
    "        evaluate(iteration, model, xv, tv, usol_tensor, error)\n",
    "\n",
    "    # Pygranso Options\n",
    "    opts = pygransoStruct()\n",
    "    nvar = getNvarTorch(model.parameters())\n",
    "    opts.x0 = nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "    opts.torch_device = device\n",
    "    opts.double_precision = False\n",
    "    opts.print_level = 1\n",
    "    opts.print_frequency = 10\n",
    "    opts.disable_terminationcode_6 = True # Important for training NNs\n",
    "    opts.maxit = max_iters\n",
    "    opts.halt_log_fn = halt_log_fn\n",
    "\n",
    "    # Hyperparameters\n",
    "    # opts.mu0 = 1\n",
    "\n",
    "    # Main algorithm\n",
    "    start = time.time()\n",
    "    soln = pygranso(var_spec= model, combined_fn = comb_fn, user_opts = opts)\n",
    "    end = time.time()\n",
    "    print(\"Total Wall Time: {}s\".format(end - start))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_output = model(grid_points)\n",
    "\n",
    "    # Plot predictions, GT, and error over the full range\n",
    "    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2,3, figsize=(18, 12))\n",
    "    outimg = test_output.cpu().detach().numpy()\n",
    "    outimg = np.reshape(outimg, (xgridsize, tgridsize))\n",
    "\n",
    "    global_min = np.min([np.min(outimg), np.min(usol_full), np.min(np.abs(outimg - usol_full))])\n",
    "    global_max = np.max([np.max(outimg), np.max(usol_full), np.max(np.abs(outimg - usol_full))])\n",
    "\n",
    "    ax1.set_title(\"Predicted outputs from PINN\")\n",
    "    ax1.set_xlabel(\"t\")\n",
    "    ax1.set_ylabel(\"x\")\n",
    "    ax1.set_box_aspect(1)\n",
    "    ax1.imshow(outimg, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax2.set_title(\"Ground truth solution from burgers_shock.mat\")\n",
    "    ax2.set_xlabel(\"t\")\n",
    "    ax2.set_ylabel(\"x\")\n",
    "    ax2.set_box_aspect(1)\n",
    "    ax2.imshow(usol_full, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax3.set_title(\"Difference\")\n",
    "    ax3.set_xlabel(\"t\")\n",
    "    ax3.set_ylabel(\"x\")\n",
    "    ax3.set_box_aspect(1)\n",
    "    ax3.imshow(usol_full - outimg, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    # Calculate gradients of network\n",
    "    testu_t, testu_x, testu_xx = get_grads(test_output, xv, tv)\n",
    "\n",
    "    testres = testu_t + torch.flatten(test_output) * testu_x - 0.01 / np.pi * testu_xx\n",
    "\n",
    "    test_ut_img = testu_t.cpu().detach().numpy()\n",
    "    test_ut_img = np.reshape(test_ut_img, (xgridsize, tgridsize))\n",
    "    test_ux_img = testu_x.cpu().detach().numpy()\n",
    "    test_ux_img = np.reshape(test_ux_img, (xgridsize, tgridsize))\n",
    "    test_res_img = testres.cpu().detach().numpy()\n",
    "    test_res_img = np.reshape(test_res_img, (xgridsize, tgridsize))\n",
    "\n",
    "    ax4.set_title(\"Predicted derivative w.r.t. t\")\n",
    "    ax4.set_xlabel(\"t\")\n",
    "    ax4.set_ylabel(\"x\")\n",
    "    ax4.set_box_aspect(1)\n",
    "    ax4.imshow(test_ut_img, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax5.set_title(\"Predicted derivative w.r.t. x\")\n",
    "    ax5.set_xlabel(\"t\")\n",
    "    ax5.set_ylabel(\"x\")\n",
    "    ax5.set_box_aspect(1)\n",
    "    ax5.imshow(test_ux_img, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax6.set_title(\"Predicted PDE residual\")\n",
    "    ax6.set_xlabel(\"t\")\n",
    "    ax6.set_ylabel(\"x\")\n",
    "    ax6.set_box_aspect(1)\n",
    "    ax6.imshow(test_res_img, extent=[0, 1, 1, -1], aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot L2 loss over full grid\n",
    "    iter_range = np.arange(1, soln.iters+1)\n",
    "    error = error.detach().cpu().numpy()\n",
    "    plt.plot(iter_range, error[:soln.iters])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Relative L2 loss\")\n",
    "    plt.show()\n"
   ],
   "id": "a742e7e7f21695a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001B[0m\u001B[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001B[0m\u001B[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001B[0m\u001B[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001B[0m\u001B[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001B[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2601                                                                     ║ \n",
      " # of inequality constraints        :      0                                                                     ║ \n",
      " # of equality constraints          :    456                                                                     ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  178.768447876 ║  0.09408710897 ║   -  │ 1.077060 ║ -  │     1 │ 0.000000 ║     1 │ 1.582521   ║ \n",
      "PyGRANSO:terminationQuadprogFailure\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/PyGRANSO/pygranso/private/bfgssqp.py\", line 607, in computeApproxStationarityVector\n",
      "    [stat_vec,n_qps,ME] = qPTC_obj.qpTerminationCondition(   self.penaltyfn_at_x, grad_samples,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/PyGRANSO/pygranso/private/qpTerminationCondition.py\", line 161, in qpTerminationCondition\n",
      "    [y,_,qps_solved,ME] = self.solveQPRobust(torch_dtype)\n",
      "    ^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: cannot unpack non-iterable NoneType object\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/PyGRANSO/pygranso/pygranso.py\", line 509, in pygranso\n",
      "    info = bfgssqp_obj.bfgssqp(penaltyfn_obj,bfgs_hess_inv_obj,opts,printer, torch_device)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/PyGRANSO/pygranso/private/bfgssqp.py\", line 428, in bfgssqp\n",
      "    [ stat_vec, self.stat_val, qps_solved, n_grad_samples,_]   = self.computeApproxStationarityVector()\n",
      "                                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/jeffreyhu/Desktop/s25/csci-5527/pygranso/PyGRANSO/pygranso/private/bfgssqp.py\", line 615, in computeApproxStationarityVector\n",
      "    stat_value = torch.linalg.vector_norm(stat_vec,ord=2).item()\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: linalg_vector_norm(): argument 'input' (position 1) must be Tensor, not NoneType\n",
      "\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'info' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnboundLocalError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 108\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[38;5;66;03m# Hyperparameters\u001B[39;00m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;66;03m# opts.mu0 = 1\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \n\u001B[1;32m    106\u001B[0m \u001B[38;5;66;03m# Main algorithm\u001B[39;00m\n\u001B[1;32m    107\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m--> 108\u001B[0m soln \u001B[38;5;241m=\u001B[39m \u001B[43mpygranso\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvar_spec\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcombined_fn\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mcomb_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_opts\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mopts\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    109\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    110\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTotal Wall Time: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124ms\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(end \u001B[38;5;241m-\u001B[39m start))\n",
      "File \u001B[0;32m~/Desktop/s25/csci-5527/pygranso/PyGRANSO/pygranso/pygranso.py:523\u001B[0m, in \u001B[0;36mpygranso\u001B[0;34m(var_spec, combined_fn, user_opts)\u001B[0m\n\u001B[1;32m    521\u001B[0m soln\u001B[38;5;241m.\u001B[39mBFGS_updates           \u001B[38;5;241m=\u001B[39m bfgs_counts\n\u001B[1;32m    522\u001B[0m soln\u001B[38;5;241m.\u001B[39mfn_evals               \u001B[38;5;241m=\u001B[39m penaltyfn_obj\u001B[38;5;241m.\u001B[39mgetNumberOfEvaluations()\n\u001B[0;32m--> 523\u001B[0m soln\u001B[38;5;241m.\u001B[39mtermination_code       \u001B[38;5;241m=\u001B[39m \u001B[43minfo\u001B[49m\u001B[38;5;241m.\u001B[39mtermination_code\n\u001B[1;32m    525\u001B[0m [qp_requests,qp_errs]       \u001B[38;5;241m=\u001B[39m getErr()\n\u001B[1;32m    526\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m qp_requests \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "\u001B[0;31mUnboundLocalError\u001B[0m: cannot access local variable 'info' where it is not associated with a value"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "be494b2bc2e5f2e7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
