{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-10T13:31:08.725084Z",
     "start_time": "2025-05-10T13:31:08.711360Z"
    }
   },
   "source": [
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct\n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "import torch.nn as nn"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T13:31:09.037586Z",
     "start_time": "2025-05-10T13:31:09.032453Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Physics-informed neural network - a straightforward MLP with tanh activations\n",
    "class PINN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers):\n",
    "        super(PINN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.linear_in = nn.Linear(input_size, hidden_size)\n",
    "        self.linear_hidden = nn.ModuleList([nn.Linear(hidden_size, hidden_size) for i in range(num_layers - 1)])\n",
    "        self.linear_out = nn.Linear(hidden_size, 1)\n",
    "        self.activ = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear_in(x)\n",
    "        x = self.activ(x)\n",
    "        for l in self.linear_hidden:\n",
    "            x = l(x)\n",
    "            x = self.activ(x)\n",
    "        out = self.linear_out(x)\n",
    "        return out\n",
    "\n",
    "# Helper function to extract gradients of the NN outputs\n",
    "def get_grads(u, x, t):\n",
    "    u_t = torch.autograd.grad(\n",
    "        u, t, \n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    u_x = torch.autograd.grad(\n",
    "        u, x,\n",
    "        grad_outputs=torch.ones_like(u),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "\n",
    "    u_xx = torch.autograd.grad(\n",
    "        u_x, x,\n",
    "        grad_outputs=torch.ones_like(u_x),\n",
    "        retain_graph=True,\n",
    "        create_graph=True\n",
    "    )[0]\n",
    "    return u_t, u_x, u_xx"
   ],
   "id": "5e478c4f701958d",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T13:31:09.419258Z",
     "start_time": "2025-05-10T13:31:09.415321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# User function specifying objective and constraints - required by PyGRANSO\n",
    "def user_fn(model, sample_points, boundary_points, boundary_usol):\n",
    "    # Forward pass for sample points\n",
    "    x, t = sample_points\n",
    "    xt = torch.cat((x, t), 1)\n",
    "    u = model(xt)\n",
    "\n",
    "    # Calculate gradients of network\n",
    "    u_t, u_x, u_xx = get_grads(u, x, t)\n",
    "\n",
    "    # Minimize residual\n",
    "    res = u_t + u * u_x - 0.01 / np.pi * u_xx\n",
    "    f = torch.sum(res ** 2)\n",
    "\n",
    "    # No inequality constraints\n",
    "    ci = None\n",
    "\n",
    "    # Equality constraint on boundary points\n",
    "    ce = pygransoStruct()\n",
    "    xb, tb = boundary_points\n",
    "    xtb = torch.cat((xb, tb), 1)\n",
    "    ub = model(xtb)\n",
    "\n",
    "    ce.c1 = ub - boundary_usol\n",
    "\n",
    "    return [f,ci,ce]"
   ],
   "id": "61b41b32e33ff79f",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-10T13:33:47.960616Z",
     "start_time": "2025-05-10T13:31:09.830572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Evaluates the relative L2 error over all grid points\n",
    "# Notably, this is NOT what the PINN is minimizing--it only has access to boundary points\n",
    "def evaluate(iteration, model, xv, tv, test_usol, error):\n",
    "    test_points = torch.stack((xv, tv)).transpose(0,1)\n",
    "    pred_usol = model(test_points)\n",
    "    L2_error = torch.sqrt(torch.sum((pred_usol - test_usol) ** 2) / torch.sum(test_usol ** 2))\n",
    "    error[iteration-1] = L2_error.cpu().detach().item()\n",
    "\n",
    "    # Save intermediate results (NN outputs + PDE residuals) as images\n",
    "    if iteration % 25 == 0:\n",
    "        outimg = pred_usol.cpu().detach().numpy()\n",
    "        outimg = np.reshape(outimg, (xgridsize, tgridsize))\n",
    "        plt.imsave(\"output_imgs/predicted_\"+str(iteration)+\".png\", outimg, origin='upper')\n",
    "        plt.close()\n",
    "        evalu_t, evalu_x, evalu_xx = get_grads(pred_usol, xv, tv)\n",
    "        evalres = evalu_t + torch.flatten(pred_usol) * evalu_x - 0.01 / np.pi * evalu_xx\n",
    "        outimg = evalres.cpu().detach().numpy()\n",
    "        outimg = np.reshape(outimg, (xgridsize, tgridsize))\n",
    "        plt.imsave(\"output_imgs/pderesidual_\"+str(iteration)+\".png\", outimg, vmin=-3, vmax=3, origin='upper')\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "    double_precision = torch.double\n",
    "    torch.manual_seed(0)\n",
    "\n",
    "    # NN hyperparams - width + depth are somewhat arbitrary and vary between papers\n",
    "    input_size = 2\n",
    "    hidden_size = 20\n",
    "    num_layers = 7\n",
    "\n",
    "    data = scipy.io.loadmat('./data/burgers_shock.mat')\n",
    "\n",
    "    # Create PINN\n",
    "    model = PINN(input_size, hidden_size, num_layers).to(device=device, dtype=double_precision)\n",
    "    model.train()\n",
    "\n",
    "    # Get boundary points along three sides (x = -1, x = 1, t = 0)\n",
    "    tb_x = data['t']\n",
    "    xb_t = data['x']\n",
    "    xb_xlow = np.full_like(tb_x, data['x'][0])\n",
    "    xb_xhigh = np.full_like(tb_x, data['x'][-1])\n",
    "    tb_tlow = np.full_like(xb_t, data['t'][0])\n",
    "\n",
    "    usol_xlow = data['usol'][0,:,None]\n",
    "    usol_xhigh = data['usol'][-1,:,None]\n",
    "    usol_tlow = data['usol'][:,0,None]\n",
    "\n",
    "    xb = np.vstack((xb_xlow, xb_xhigh, xb_t))\n",
    "    tb = np.vstack((tb_x, tb_x, tb_tlow))\n",
    "    usolb = np.vstack((usol_xlow, usol_xhigh, usol_tlow))\n",
    "\n",
    "    xb = torch.Tensor(xb).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    tb = torch.Tensor(tb).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    usolb = torch.Tensor(usolb).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    boundary_points = (xb, tb)\n",
    "\n",
    "    # Ground-truth data - used for testing/evaluation\n",
    "    usol_full = data['usol']\n",
    "    usol_tensor = usol_full.flatten()\n",
    "    usol_tensor = torch.Tensor(usol_tensor).to(device=device, dtype=double_precision)\n",
    "\n",
    "    # Sample points. Following Dual-Cone Gradient Descent, 10x as many sample points as boundary points\n",
    "    n_samples = 4560\n",
    "    xs = -1 + 2 * np.random.rand(n_samples, 1)\n",
    "    ts = np.random.rand(n_samples, 1)\n",
    "\n",
    "    xs = torch.Tensor(xs).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    ts = torch.Tensor(ts).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    sample_points = (xs, ts)\n",
    "\n",
    "    # Create grid inputs for visualization, comparison to GT\n",
    "    xgridsize = 256\n",
    "    tgridsize = 100\n",
    "    tv, xv = np.meshgrid(data['t'], data['x'])\n",
    "    tv = torch.Tensor(tv.flatten()).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    xv = torch.Tensor(xv.flatten()).to(device=device, dtype=double_precision).requires_grad_()\n",
    "    grid_points = torch.stack((xv, tv)).transpose(0,1)\n",
    "\n",
    "    # Tensors have fixed size and we need to modify in-place, so initialize with maximum possible size\n",
    "    max_iters = 200\n",
    "    error = torch.empty(max_iters, device=device, dtype=double_precision)\n",
    "\n",
    "    # Functions for optimizer\n",
    "    comb_fn = lambda model: user_fn(model, sample_points, boundary_points, usolb)\n",
    "    halt_log_fn = lambda iteration, x, penaltyfn_parts, d,get_BFGS_state_fn, H_regularized, ls_evals, alpha, n_gradients, stat_vec, stat_val, fallback_level: \\\n",
    "        evaluate(iteration, model, xv, tv, usol_tensor, error)\n",
    "\n",
    "    # Pygranso Options\n",
    "    opts = pygransoStruct()\n",
    "    nvar = getNvarTorch(model.parameters())\n",
    "    opts.x0 = nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "    opts.torch_device = device\n",
    "    opts.print_level = 1\n",
    "    opts.print_frequency = 10\n",
    "    opts.disable_terminationcode_6 = True # Important for training NNs\n",
    "    opts.maxit = max_iters\n",
    "    opts.halt_log_fn = halt_log_fn\n",
    "\n",
    "    # Hyperparameters\n",
    "    # opts.mu0 = 1\n",
    "\n",
    "    # Main algorithm\n",
    "    start = time.time()\n",
    "    soln = pygranso(var_spec= model, combined_fn = comb_fn, user_opts = opts)\n",
    "    end = time.time()\n",
    "    print(\"Total Wall Time: {}s\".format(end - start))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    test_output = model(grid_points)\n",
    "\n",
    "    # Plot predictions, GT, and error over the full range\n",
    "    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2,3, figsize=(18, 12))\n",
    "    outimg = test_output.cpu().detach().numpy()\n",
    "    outimg = np.reshape(outimg, (xgridsize, tgridsize))\n",
    "\n",
    "    global_min = np.min([np.min(outimg), np.min(usol_full), np.min(np.abs(outimg - usol_full))])\n",
    "    global_max = np.max([np.max(outimg), np.max(usol_full), np.max(np.abs(outimg - usol_full))])\n",
    "\n",
    "    ax1.set_title(\"Predicted outputs from PINN\")\n",
    "    ax1.set_xlabel(\"t\")\n",
    "    ax1.set_ylabel(\"x\")\n",
    "    ax1.set_box_aspect(1)\n",
    "    ax1.imshow(outimg, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax2.set_title(\"Ground truth solution from burgers_shock.mat\")\n",
    "    ax2.set_xlabel(\"t\")\n",
    "    ax2.set_ylabel(\"x\")\n",
    "    ax2.set_box_aspect(1)\n",
    "    ax2.imshow(usol_full, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax3.set_title(\"Difference\")\n",
    "    ax3.set_xlabel(\"t\")\n",
    "    ax3.set_ylabel(\"x\")\n",
    "    ax3.set_box_aspect(1)\n",
    "    ax3.imshow(usol_full - outimg, vmin=global_min, vmax=global_max, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    # Calculate gradients of network\n",
    "    testu_t, testu_x, testu_xx = get_grads(test_output, xv, tv)\n",
    "\n",
    "    testres = testu_t + torch.flatten(test_output) * testu_x - 0.01 / np.pi * testu_xx\n",
    "\n",
    "    test_ut_img = testu_t.cpu().detach().numpy()\n",
    "    test_ut_img = np.reshape(test_ut_img, (xgridsize, tgridsize))\n",
    "    test_ux_img = testu_x.cpu().detach().numpy()\n",
    "    test_ux_img = np.reshape(test_ux_img, (xgridsize, tgridsize))\n",
    "    test_res_img = testres.cpu().detach().numpy()\n",
    "    test_res_img = np.reshape(test_res_img, (xgridsize, tgridsize))\n",
    "\n",
    "    ax4.set_title(\"Predicted derivative w.r.t. t\")\n",
    "    ax4.set_xlabel(\"t\")\n",
    "    ax4.set_ylabel(\"x\")\n",
    "    ax4.set_box_aspect(1)\n",
    "    ax4.imshow(test_ut_img, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax5.set_title(\"Predicted derivative w.r.t. x\")\n",
    "    ax5.set_xlabel(\"t\")\n",
    "    ax5.set_ylabel(\"x\")\n",
    "    ax5.set_box_aspect(1)\n",
    "    ax5.imshow(test_ux_img, extent=[0, 1, 1, -1], aspect='auto')\n",
    "\n",
    "    ax6.set_title(\"Predicted PDE residual\")\n",
    "    ax6.set_xlabel(\"t\")\n",
    "    ax6.set_ylabel(\"x\")\n",
    "    ax6.set_box_aspect(1)\n",
    "    ax6.imshow(test_res_img, extent=[0, 1, 1, -1], aspect='auto')\n",
    "    plt.show()\n",
    "\n",
    "    # Plot L2 loss over full grid\n",
    "    iter_range = np.arange(1, soln.iters+1)\n",
    "    error = error.detach().cpu().numpy()\n",
    "    plt.plot(iter_range, error[:soln.iters])\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Relative L2 loss\")\n",
    "    plt.show()\n"
   ],
   "id": "a742e7e7f21695a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001B[0m\u001B[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001B[0m\u001B[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001B[0m\u001B[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001B[0m\u001B[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001B[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2601                                                                     ║ \n",
      " # of inequality constraints        :      0                                                                     ║ \n",
      " # of equality constraints          :    456                                                                     ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  178.768518554 ║  0.09414975563 ║   -  │ 1.077060 ║ -  │     1 │ 0.000000 ║     1 │ 1.582005   ║ \n",
      "Solver interrupted\n",
      "Solver interrupted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "da0734f5266e4bdb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
