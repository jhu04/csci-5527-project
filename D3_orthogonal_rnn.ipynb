{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5257bb27",
   "metadata": {},
   "source": [
    "# Orthogonal RNN\n",
    "\n",
    "Train Orthogonal RNN for MNIST classification based on [this Paper](https://arxiv.org/pdf/1901.08428.pdf)\n",
    "\n",
    "NOTE: this example is still under development. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c859c154",
   "metadata": {},
   "source": [
    "## Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96269c7",
   "metadata": {},
   "source": [
    "For each element in the input sequence, each layer computes the following function:\n",
    "$$h_t=\\tanh(W_{ih}x_t+b_{ih}+W_{hh}h_{t-1}+b_hh)$$\n",
    "\n",
    "where $h_{t}$ is the hidden state at time $t$, and $h_{t-1}$ is the hidden state of the previous layer at time $t-1$ or the initial hidden state at time $o$. \n",
    "\n",
    "For each layer, we have the orthogonal constraint:\n",
    "$$ W_{hh}^T W_{hh} = I $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dfdd50",
   "metadata": {},
   "source": [
    "## Modules Importing\n",
    "Import all necessary modules and add PyGRANSO src folder to system path. "
   ]
  },
  {
   "cell_type": "code",
   "id": "90ed32f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T06:53:07.921978Z",
     "start_time": "2025-03-22T06:53:06.562626Z"
    }
   },
   "source": [
    "import time\n",
    "import torch\n",
    "import sys\n",
    "## Adding PyGRANSO directories. Should be modified by user\n",
    "sys.path.append('.')\n",
    "from pygranso.pygranso import pygranso\n",
    "from pygranso.pygransoStruct import pygransoStruct \n",
    "from pygranso.private.getNvar import getNvarTorch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from pygranso.private.getObjGrad import getObjGradDL"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "17a1b7fe",
   "metadata": {},
   "source": [
    "## Data Initialization \n",
    "Specify torch device, neural network architecture, and generate data.\n",
    "\n",
    "NOTE: please specify path for downloading data.\n",
    "\n",
    "Use GPU for this problem. If no cuda device available, please set *device = torch.device('cpu')*"
   ]
  },
  {
   "cell_type": "code",
   "id": "8b4842e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T07:25:30.763232Z",
     "start_time": "2025-03-22T07:25:28.399442Z"
    }
   },
   "source": [
    "device = torch.device('cpu')\n",
    "\n",
    "sequence_length = 28\n",
    "input_size = 28\n",
    "hidden_size = 30\n",
    "num_layers = 1\n",
    "num_classes = 10\n",
    "batch_size = 100\n",
    "\n",
    "\n",
    "double_precision = torch.double\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.reshape(x,(batch_size,sequence_length,input_size))\n",
    "        # Set initial hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device=device, dtype=double_precision)\n",
    "        out, hidden = self.rnn(x, h0)  # out: tensor of shape (batch_size, seq_length, hidden_size)\n",
    "        #Reshaping the outputs such that it can be fit into the fully connected layer\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "    \n",
    "torch.manual_seed(0)\n",
    "\n",
    "model = RNN(input_size, hidden_size, num_layers, num_classes).to(device=device, dtype=double_precision)\n",
    "model.train()\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = './examples/data/mnist',\n",
    "    train = True,                         \n",
    "    transform = ToTensor(), \n",
    "    download = True,            \n",
    ") \n",
    "\n",
    "loaders = {\n",
    "    'train' : torch.utils.data.DataLoader(train_data, \n",
    "                                        batch_size=100, \n",
    "                                        shuffle=True, \n",
    "                                        num_workers=1),\n",
    "}\n",
    "\n",
    "inputs, labels = next(iter(loaders['train']))\n",
    "inputs, labels = inputs.reshape(-1, sequence_length, input_size).to(device=device, dtype=double_precision), labels.to(device=device)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "id": "ec80716b",
   "metadata": {},
   "source": [
    "## Function Set-Up\n",
    "\n",
    "Encode the optimization variables, and objective and constraint functions.\n",
    "\n",
    "Note: please strictly follow the format of comb_fn, which will be used in the PyGRANSO main algortihm."
   ]
  },
  {
   "cell_type": "code",
   "id": "fb360e75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T07:25:30.769516Z",
     "start_time": "2025-03-22T07:25:30.765688Z"
    }
   },
   "source": [
    "def user_fn(model,inputs,labels):\n",
    "    # objective function    \n",
    "    logits = model(inputs)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    f = criterion(logits, labels)\n",
    "\n",
    "    A = list(model.parameters())[1]\n",
    "\n",
    "    # inequality constraint\n",
    "    ci = None\n",
    "\n",
    "    # equality constraint \n",
    "    # special orthogonal group\n",
    "    \n",
    "    ce = pygransoStruct()\n",
    "\n",
    "    c1_vec = (A.T @ A \n",
    "              - torch.eye(hidden_size)\n",
    "              .to(device=device, dtype=double_precision)\n",
    "             ).reshape(1,-1)\n",
    "    \n",
    "    ce.c1 = torch.linalg.vector_norm(c1_vec,2) # l2 folding to reduce the total number of constraints\n",
    "    # ce.c2 = torch.det(A) - 1\n",
    "\n",
    "    # ce = None\n",
    "\n",
    "    return [f,ci,ce]\n",
    "\n",
    "comb_fn = lambda model : user_fn(model,inputs,labels)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "markdown",
   "id": "f0f55ace",
   "metadata": {},
   "source": [
    "## User Options\n",
    "Specify user-defined options for PyGRANSO "
   ]
  },
  {
   "cell_type": "code",
   "id": "f3a65b57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T07:25:30.775538Z",
     "start_time": "2025-03-22T07:25:30.770912Z"
    }
   },
   "source": [
    "opts = pygransoStruct()\n",
    "opts.torch_device = device\n",
    "nvar = getNvarTorch(model.parameters())\n",
    "opts.x0 = torch.nn.utils.parameters_to_vector(model.parameters()).detach().reshape(nvar,1)\n",
    "opts.opt_tol = 1e-3\n",
    "opts.viol_eq_tol = 1e-4\n",
    "# opts.maxit = 150\n",
    "# opts.fvalquit = 1e-6\n",
    "opts.print_level = 1\n",
    "opts.print_frequency = 50\n",
    "# opts.print_ascii = True\n",
    "# opts.limited_mem_size = 100\n",
    "opts.double_precision = True\n",
    "opts.maxit = 10\n",
    "\n",
    "opts.mu0 = 1"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "markdown",
   "id": "754ba30a",
   "metadata": {},
   "source": [
    "## Initial Test \n",
    "Check initial accuracy of the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "id": "711f0e9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T07:25:30.785145Z",
     "start_time": "2025-03-22T07:25:30.777732Z"
    }
   },
   "source": [
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Initial acc = {:.2f}%\".format((100 * correct/len(inputs))))  "
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial acc = 10.00%\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "id": "8bca18c7",
   "metadata": {},
   "source": [
    "## Main Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "id": "632976b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T07:25:31.842538Z",
     "start_time": "2025-03-22T07:25:31.270997Z"
    }
   },
   "source": [
    "start = time.time()\n",
    "soln = pygranso(var_spec= model, combined_fn = comb_fn, user_opts = opts)\n",
    "end = time.time()\n",
    "print(\"Total Wall Time: {}s\".format(end - start))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[33m╔═════ QP SOLVER NOTICE ════════════════════════════════════════════════════════════════════════╗\n",
      "\u001B[0m\u001B[33m║  PyGRANSO requires a quadratic program (QP) solver that has a quadprog-compatible interface,  ║\n",
      "\u001B[0m\u001B[33m║  the default is osqp. Users may provide their own wrapper for the QP solver.                  ║\n",
      "\u001B[0m\u001B[33m║  To disable this notice, set opts.quadprog_info_msg = False                                   ║\n",
      "\u001B[0m\u001B[33m╚═══════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "\u001B[0m═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╗\n",
      "PyGRANSO: A PyTorch-enabled port of GRANSO with auto-differentiation                                             ║ \n",
      "Version 1.2.0                                                                                                    ║ \n",
      "Licensed under the AGPLv3, Copyright (C) 2021-2022 Tim Mitchell and Buyun Liang                                  ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╣\n",
      "Problem specifications:                                                                                          ║ \n",
      " # of variables                     :   2110                                                                     ║ \n",
      " # of inequality constraints        :      0                                                                     ║ \n",
      " # of equality constraints          :      1                                                                     ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "     ║ <--- Penalty Function --> ║                ║ Total Violation ║ <--- Line Search ---> ║ <- Stationarity -> ║ \n",
      "Iter ║    Mu    │      Value     ║    Objective   ║ Ineq │    Eq    ║ SD │ Evals │     t    ║ Grads │    Value   ║ \n",
      "═════╬═══════════════════════════╬════════════════╬═════════════════╬═══════════════════════╬════════════════════╣\n",
      "   0 ║ 1.000000 │  6.34479003561 ║  2.28955713337 ║   -  │ 4.055233 ║ -  │     1 │ 0.000000 ║     1 │ 0.727032   ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "F = final iterate, B = Best (to tolerance), MF = Most Feasible                                                   ║ \n",
      "Optimization results:                                                                                            ║ \n",
      "═════╦═══════════════════════════╦════════════════╦═════════════════╦═══════════════════════╦════════════════════╣\n",
      "   F ║          │                ║  1.97022085157 ║   -  │ 1.272535 ║    │       │          ║       │            ║ \n",
      "  MF ║          │                ║  2.01493479641 ║   -  │ 1.229934 ║    │       │          ║       │            ║ \n",
      "═════╩═══════════════════════════╩════════════════╩═════════════════╩═══════════════════════╩════════════════════╣\n",
      "Iterations:              10                                                                                      ║ \n",
      "Function evaluations:    18                                                                                      ║ \n",
      "PyGRANSO termination code: 4 --- max iterations reached.                                                         ║ \n",
      "═════════════════════════════════════════════════════════════════════════════════════════════════════════════════╝\n",
      "Total Wall Time: 0.5692627429962158s\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "markdown",
   "id": "21bff5fd",
   "metadata": {},
   "source": [
    "## Train Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "id": "8d846f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T07:25:33.775191Z",
     "start_time": "2025-03-22T07:25:33.764597Z"
    }
   },
   "source": [
    "torch.nn.utils.vector_to_parameters(soln.final.x, model.parameters())\n",
    "logits = model(inputs)\n",
    "_, predicted = torch.max(logits.data, 1)\n",
    "correct = (predicted == labels).sum().item()\n",
    "print(\"Final acc = {:.2f}%\".format((100 * correct/len(inputs))))  \n",
    "print(\"final feasibility = {}\".format(soln.final.tve))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final acc = 48.00%\n",
      "final feasibility = 1.2725352321341625\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7db137fd12fb471c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
